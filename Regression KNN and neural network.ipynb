{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "\n",
    "*  The regression algorithms contained in this notebook are K nearest neighbor and neural network(keras).\n",
    "*  The original data is standardized and then trained with the regressors. \n",
    "\n",
    "\n",
    "**Evaluation metric** The evaluation metric is `PRE(Proportion of reduction in error)` which is defined as:\n",
    "$\\frac{MSE_{baseline}-MSE_{regression}}{MSE_{baseline}}$\n",
    "\n",
    "where $MSE_{baseline}$ is the Mean squared error of estimating with sample mean and $MSE_{regression}$ is the Mean squared error of estimating with regressor(ie.NN,KNN). The PRE is a the percentage of reduction in error which mostly ranges from 0 to 1.Note that this value could be negative if our model perform worse than using the sample mean.\n",
    "\n",
    "**Missing value**:Impute with mean of the column(for numeric) and the mode of the column(for categorical).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graduate admission rate: \n",
    "## KNN:75% reduction in error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libaries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use 10 neighbors\n",
    "def Knn_estimator(x,y,n_neigh=10,weights='uniform',algo='auto',p=2):\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "    x_std=scaler.fit_transform(x)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_std, y, test_size=0.3)\n",
    "    \n",
    "    neigh=KNeighborsRegressor(n_neighbors=n_neigh,weights=weights,algorithm=algo,p=p)\n",
    "    neigh.fit(X_train,y_train)\n",
    "    \n",
    "    pred_with_mean=[sum(y_test)/len(y_test)]*len(y_test)\n",
    "    baseline=mean_squared_error(y_test,pred_with_mean)\n",
    "    \n",
    "    pred_mse=mean_squared_error(list(y_test),neigh.predict(X_test))\n",
    "    r_square=(baseline-pred_mse)/baseline\n",
    "    \n",
    "    print(\"Baseline MSE:\",round(baseline,4),\"KNN MSE:\",round(pred_mse,4),\"PRE:\",round(r_square,4))\n",
    "    return r_square\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 0.0196 KNN MSE: 0.0046 PRE: 0.7651\n",
      "Baseline MSE: 0.0239 KNN MSE: 0.0057 PRE: 0.7638\n",
      "Baseline MSE: 0.0213 KNN MSE: 0.0054 PRE: 0.7467\n",
      "Baseline MSE: 0.025 KNN MSE: 0.0061 PRE: 0.7546\n",
      "Baseline MSE: 0.0194 KNN MSE: 0.0044 PRE: 0.7717\n",
      "Baseline MSE: 0.02 KNN MSE: 0.0064 PRE: 0.68\n",
      "Baseline MSE: 0.0204 KNN MSE: 0.0042 PRE: 0.7942\n",
      "Baseline MSE: 0.0191 KNN MSE: 0.0043 PRE: 0.7739\n",
      "Baseline MSE: 0.0196 KNN MSE: 0.0059 PRE: 0.6991\n",
      "Baseline MSE: 0.0164 KNN MSE: 0.0041 PRE: 0.75\n",
      "Overall PRE over 10 trials: 0.749932411216001\n"
     ]
    }
   ],
   "source": [
    "#import data\n",
    "admission_rate=pd.read_csv('C:/Users/zhenguo/Desktop/STA141C/Admission_Predict.csv')\n",
    "y=admission_rate['Chance of Admit ']\n",
    "x=admission_rate.iloc[:,1:8]\n",
    "\n",
    "overall=sum([Knn_estimator(x,y) for i in range(10)])/10\n",
    "print(\"Overall PRE over 10 trials:\",overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression with Neural Network(Keras): 54%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhenguo\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use no hidden layers since it is a small dataset, 30 iteration.\n",
    "def keras_model():\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_std, y, test_size=0.3)\n",
    "    model=Sequential()\n",
    "    model.add(Dense(7,input_dim=7,activation='relu',kernel_initializer='normal'))\n",
    "    model.add(Dense(1,kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "    history=model.fit(X_train,y_train,epochs=30,validation_split=0.1,verbose=0)\n",
    "    pred=model.predict(X_test)\n",
    "\n",
    "    pred_with_mean=[sum(y_test)/len(y_test)]*len(y_test)\n",
    "    baseline=mean_squared_error(y_test,pred_with_mean)\n",
    "    pred_mse=mean_squared_error(list(y_test),pred)    \n",
    "    r_square=(baseline-pred_mse)/baseline\n",
    "    print(\"Baseline MSE:\",round(baseline,4),\"Keras MSE:\",round(pred_mse,4),\"PRE:\",round(r_square,4))\n",
    "    return r_square\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 0.0214 Keras MSE: 0.0105 PRE: 0.5086\n",
      "Baseline MSE: 0.02 Keras MSE: 0.009 PRE: 0.5482\n",
      "Baseline MSE: 0.017 Keras MSE: 0.0072 PRE: 0.5765\n",
      "Baseline MSE: 0.0193 Keras MSE: 0.0083 PRE: 0.5709\n",
      "Baseline MSE: 0.0186 Keras MSE: 0.0081 PRE: 0.5677\n",
      "Baseline MSE: 0.0182 Keras MSE: 0.0082 PRE: 0.5523\n",
      "Baseline MSE: 0.0218 Keras MSE: 0.0099 PRE: 0.5477\n",
      "Baseline MSE: 0.0196 Keras MSE: 0.01 PRE: 0.4901\n",
      "Baseline MSE: 0.0221 Keras MSE: 0.011 PRE: 0.4997\n",
      "Baseline MSE: 0.0192 Keras MSE: 0.0079 PRE: 0.5918\n",
      "Overall PRE over 10 trials: 0.5453546316152135\n"
     ]
    }
   ],
   "source": [
    "overall=sum([keras_model() for i in range(10)])/10\n",
    "print(\"Overall PRE over 10 trials:\",overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary for `Admission`:**\n",
    "* Dataset characteristics: small-scale, low dimension, numeric attributes\n",
    "* Result: KNN(75%) outperforms neural network(54%) in both recduction in error and computational time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crime incidence in community\n",
    "### KNN:58% reduction in error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 405784.2056 KNN MSE: 188459.6628 PRE: 0.5356\n",
      "Baseline MSE: 354282.6461 KNN MSE: 150688.9022 PRE: 0.5747\n",
      "Baseline MSE: 386027.6508 KNN MSE: 158331.6898 PRE: 0.5898\n",
      "Baseline MSE: 384972.0335 KNN MSE: 153695.831 PRE: 0.6008\n",
      "Baseline MSE: 454711.4389 KNN MSE: 205837.6454 PRE: 0.5473\n",
      "Baseline MSE: 376035.4971 KNN MSE: 156647.2317 PRE: 0.5834\n",
      "Baseline MSE: 390505.3232 KNN MSE: 152794.9659 PRE: 0.6087\n",
      "Baseline MSE: 340393.6825 KNN MSE: 152998.8462 PRE: 0.5505\n",
      "Baseline MSE: 305672.3447 KNN MSE: 128184.1639 PRE: 0.5806\n",
      "Baseline MSE: 470380.1817 KNN MSE: 208468.2079 PRE: 0.5568\n",
      "Overall PRE over 10 trials: 0.572828950213284\n"
     ]
    }
   ],
   "source": [
    "crime=pd.read_csv('C:/Users/zhenguo/Desktop/STA141C/Violent_Crime_pred.csv')\n",
    "#subseting the data\n",
    "x=crime.iloc[:,2:-1]\n",
    "y=crime['target']\n",
    "\n",
    "#check the missing valuings in each column\n",
    "#preliminary decision: remove the columns with 1675(over 80%) missing values,to be discussed\n",
    "x.iloc[:,np.sort(x.isna().sum())==0]\n",
    "\n",
    "x=x.dropna(axis='columns')\n",
    "\n",
    "\n",
    "overall=sum([Knn_estimator(x,y,n_neigh=10) for i in range(10)])/10\n",
    "print(\"Overall PRE over 10 trials:\",overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network: 60% reduction in error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model():\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "    x_std=scaler.fit_transform(x)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_std, y, test_size=0.3)\n",
    "    model=Sequential()\n",
    "    model.add(Dense(101,input_dim=101,activation='relu',kernel_initializer='normal'))\n",
    "    model.add(Dense(30,input_dim=101,activation='relu',kernel_initializer='normal'))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(Adam(lr=0.001),loss='mean_squared_error',metrics=['mse'])\n",
    "    history=model.fit(X_train,y_train,batch_size=50,epochs=100,validation_split=0.1,verbose=0)\n",
    "    pred=model.predict(X_test)\n",
    "\n",
    "    pred_with_mean=[sum(y_test)/len(y_test)]*len(y_test)\n",
    "    baseline=mean_squared_error(y_test,pred_with_mean)\n",
    "    pred_mse=mean_squared_error(list(y_test),pred)    \n",
    "    r_square=(baseline-pred_mse)/baseline\n",
    "    print(\"Baseline MSE:\",round(baseline,4),\"Keras MSE:\",round(pred_mse,4),\"PRE:\",round(r_square,4))\n",
    "    return r_square\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 399407.9197 Keras MSE: 174416.6583 PRE: 0.5633\n",
      "Baseline MSE: 392564.8185 Keras MSE: 159461.854 PRE: 0.5938\n",
      "Baseline MSE: 374590.9379 Keras MSE: 149265.7801 PRE: 0.6015\n",
      "Baseline MSE: 411878.5184 Keras MSE: 168782.0356 PRE: 0.5902\n",
      "Baseline MSE: 333814.1456 Keras MSE: 126122.4371 PRE: 0.6222\n",
      "Baseline MSE: 373999.8708 Keras MSE: 134377.3122 PRE: 0.6407\n",
      "Baseline MSE: 400469.2474 Keras MSE: 139923.6825 PRE: 0.6506\n",
      "Baseline MSE: 355732.0766 Keras MSE: 137451.6639 PRE: 0.6136\n",
      "Baseline MSE: 315501.8113 Keras MSE: 129092.1408 PRE: 0.5908\n",
      "Baseline MSE: 328360.6527 Keras MSE: 144484.4955 PRE: 0.56\n",
      "Overall PRE over 10 trials: 0.6026751535581809\n"
     ]
    }
   ],
   "source": [
    "overall=sum([keras_model() for i in range(10)])/10\n",
    "print(\"Overall PRE over 10 trials:\",overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary for `Crime`:**\n",
    "* Dataset characteristics: Medium-scale, relatively high dimension with irrelavant features, numeric attributes\n",
    "**Result:** \n",
    "*  KNN(58%): faster run time\n",
    "*  Neural network(60%): Takes longer to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automobile: categorical and numerical variables\n",
    "## KNN: 80% reduction in error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhenguo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Cleaning data,process missing values\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import Imputer\n",
    "cars=pd.read_csv('C:/Users/zhenguo/Desktop/STA141C/automobile.csv')\n",
    "cars=cars.replace('?',np.nan).iloc[:,3:] #replace ? with NaN\n",
    "cars['X6'][cars['X6'].isna()]='four' #mode is four, assign four to the missing value\n",
    "impute=Imputer(strategy='mean') #use column mean to impute missing value\n",
    "cars[['X19','X20','X22','X23']]=impute.fit_transform(cars[['X19','X20','X22','X23']])\n",
    "pd.isna(cars).sum() #now no missing values\n",
    "x=cars.iloc[:,0:-1]\n",
    "y=cars.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 69981239.011 KNN MSE: 11444136.4426 PRE: 0.8365\n",
      "Baseline MSE: 81672005.7834 KNN MSE: 14215479.2951 PRE: 0.8259\n",
      "Baseline MSE: 51954682.5477 KNN MSE: 11094325.9344 PRE: 0.7865\n",
      "Baseline MSE: 47282803.7974 KNN MSE: 6081208.7049 PRE: 0.8714\n",
      "Baseline MSE: 51406837.663 KNN MSE: 9430858.1639 PRE: 0.8165\n",
      "Baseline MSE: 75303550.7025 KNN MSE: 5121470.0 PRE: 0.932\n",
      "Baseline MSE: 63408579.3496 KNN MSE: 38669133.8525 PRE: 0.3902\n",
      "Baseline MSE: 71592368.7073 KNN MSE: 10376146.8525 PRE: 0.8551\n",
      "Baseline MSE: 62816203.9307 KNN MSE: 11952412.541 PRE: 0.8097\n",
      "Baseline MSE: 78273393.2959 KNN MSE: 9037491.3934 PRE: 0.8845\n",
      "Overall PRE over 10 trials: 0.8008283461053187\n"
     ]
    }
   ],
   "source": [
    "#get categorical column\n",
    "cate_col=list(x.columns[x.dtypes=='object'])\n",
    "x=pd.get_dummies(x,columns=cate_col) #create dummy variables for the categorical var\n",
    "\n",
    "overall=sum([Knn_estimator(x,y,n_neigh=1) for i in range(10)])/10\n",
    "print(\"Overall PRE over 10 trials:\",overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "## Reduction in error:85%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model():\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "    x_std=scaler.fit_transform(x)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_std, y, test_size=0.3)\n",
    "\n",
    "    model=Sequential()\n",
    "    model.add(Dense(72,input_dim=72,activation='relu',kernel_initializer='normal'))\n",
    "    model.add(Dense(30,input_dim=72,activation='relu',kernel_initializer='normal'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(Adam(lr=0.01),loss='mean_squared_error',metrics=['mse'])\n",
    "    history=model.fit(X_train,y_train,batch_size=10,epochs=100,validation_split=0.1,verbose=0)\n",
    "\n",
    "    pred=model.predict(X_test)\n",
    "    pred_with_mean=[sum(y_test)/len(y_test)]*len(y_test)\n",
    "    baseline=mean_squared_error(y_test,pred_with_mean)\n",
    "    pred_mse=mean_squared_error(list(y_test),pred)    \n",
    "    r_square=(baseline-pred_mse)/baseline\n",
    "    print(\"Baseline MSE:\",round(baseline,4),\"Keras MSE:\",round(pred_mse,4),\"PRE:\",round(r_square,4))\n",
    "    return r_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 51809612.8729 Keras MSE: 12573943.5237 PRE: 0.7573\n",
      "Baseline MSE: 54178137.5243 Keras MSE: 8323390.5802 PRE: 0.8464\n",
      "Baseline MSE: 59519766.9782 Keras MSE: 6269259.7456 PRE: 0.8947\n",
      "Baseline MSE: 55601864.5402 Keras MSE: 4921577.871 PRE: 0.9115\n",
      "Baseline MSE: 87577031.1508 Keras MSE: 11983410.8109 PRE: 0.8632\n",
      "Baseline MSE: 42201287.0314 Keras MSE: 6483283.4757 PRE: 0.8464\n",
      "Baseline MSE: 78607754.738 Keras MSE: 20062081.2037 PRE: 0.7448\n",
      "Baseline MSE: 35341461.3255 Keras MSE: 4332851.3296 PRE: 0.8774\n",
      "Baseline MSE: 63590487.4394 Keras MSE: 7154329.5737 PRE: 0.8875\n",
      "Baseline MSE: 65787990.5751 Keras MSE: 4981221.9195 PRE: 0.9243\n",
      "Overall PRE over 10 trials: 0.8553329174253268\n"
     ]
    }
   ],
   "source": [
    "overall=sum([keras_model() for i in range(10)])/10\n",
    "print(\"Overall PRE over 10 trials:\",overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary for `Automobile`:**\n",
    "* Dataset characteristics: small-scale, low dimension, numeric and categorical attributes\n",
    "**Result:**\n",
    "*  KNN(80%)\n",
    "*  Neural network(85%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mercede: sparse data with binary variables and categorical variables\n",
    "## KNN:42%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209, 563)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pass_test=pd.read_csv('C:/Users/zhenguo/Desktop/STA141C/pass_testing.csv')\n",
    "# pass_test.shape #4209 by 378\n",
    "# pd.isna(pass_test).sum().sum() #no missing value\n",
    "\n",
    "x=pass_test.iloc[:,2:]\n",
    "y=pass_test['y']\n",
    "cate_col=list(x.columns[x.dtypes=='object'])\n",
    "x=pd.get_dummies(x,columns=cate_col) #change categorical variables to dummy var\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 166.8287 KNN MSE: 99.6932 PRE: 0.4024\n",
      "Baseline MSE: 155.9393 KNN MSE: 86.065 PRE: 0.4481\n",
      "Baseline MSE: 172.868 KNN MSE: 110.6822 PRE: 0.3597\n",
      "Baseline MSE: 178.119 KNN MSE: 108.3273 PRE: 0.3918\n",
      "Baseline MSE: 166.2521 KNN MSE: 92.9012 PRE: 0.4412\n",
      "Baseline MSE: 149.669 KNN MSE: 83.1095 PRE: 0.4447\n",
      "Baseline MSE: 167.5927 KNN MSE: 93.5079 PRE: 0.4421\n",
      "Baseline MSE: 153.6807 KNN MSE: 87.8013 PRE: 0.4287\n",
      "Baseline MSE: 163.8447 KNN MSE: 89.3852 PRE: 0.4545\n",
      "Baseline MSE: 151.655 KNN MSE: 80.0287 PRE: 0.4723\n",
      "Overall PRE over 10 trials: 0.4285458044504349\n"
     ]
    }
   ],
   "source": [
    "overall=sum([Knn_estimator(x,y,n_neigh=20) for i in range(10)])/10\n",
    "print(\"Overall PRE over 10 trials:\",overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network:53%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model():\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "    x_std=scaler.fit_transform(x)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_std, y, test_size=0.3)\n",
    "\n",
    "    model=Sequential()\n",
    "    model.add(Dense(563,input_dim=563,activation='relu',kernel_initializer='normal'))\n",
    "    model.add(Dense(50,input_dim=100,activation='relu',kernel_initializer='normal'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(Adam(lr=0.0001),loss='mean_squared_error',metrics=['mse'])\n",
    "    history=model.fit(X_train,y_train,batch_size=60,epochs=40,validation_split=0.1,verbose=0)\n",
    "\n",
    "    pred=model.predict(X_test)\n",
    "    pred_with_mean=[sum(y_test)/len(y_test)]*len(y_test)\n",
    "    baseline=mean_squared_error(y_test,pred_with_mean)\n",
    "    pred_mse=mean_squared_error(list(y_test),pred)    \n",
    "    r_square=(baseline-pred_mse)/baseline\n",
    "    print(\"Baseline MSE:\",round(baseline,4),\"Keras MSE:\",round(pred_mse,4),\"PRE:\",round(r_square,4))\n",
    "    return r_square\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 154.4703 Keras MSE: 74.9101 PRE: 0.5151\n",
      "Baseline MSE: 157.3397 Keras MSE: 69.7739 PRE: 0.5565\n",
      "Baseline MSE: 162.5573 Keras MSE: 74.1338 PRE: 0.544\n",
      "Baseline MSE: 155.1553 Keras MSE: 73.516 PRE: 0.5262\n",
      "Baseline MSE: 170.2172 Keras MSE: 88.6884 PRE: 0.479\n",
      "Baseline MSE: 159.3436 Keras MSE: 69.6261 PRE: 0.563\n",
      "Baseline MSE: 169.3383 Keras MSE: 83.6642 PRE: 0.5059\n",
      "Baseline MSE: 156.3171 Keras MSE: 70.6824 PRE: 0.5478\n",
      "Baseline MSE: 147.8653 Keras MSE: 65.0646 PRE: 0.56\n",
      "Baseline MSE: 152.6489 Keras MSE: 66.336 PRE: 0.5654\n",
      "Overall PRE over 10 trials: 0.536290524387286\n"
     ]
    }
   ],
   "source": [
    "overall=sum([keras_model() for i in range(10)])/10\n",
    "print(\"Overall PRE over 10 trials:\",overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary for `Mercedes`:**\n",
    "* Dataset characteristics: medium scale, high dimension, sparse attributes.\n",
    "**Result:**\n",
    "*  KNN(42%)\n",
    "*  Neural network(54%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text data(extra dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "price=pd.read_csv('C:/Users/zhenguo/Desktop/STA141C/price_predict_reduced.csv',encoding='ISO-8859-1')\n",
    "price=price.dropna()\n",
    "import re\n",
    "import nltk\n",
    "#nltk.download()\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem.snowball import FrenchStemmer \n",
    "stemmer =FrenchStemmer() \n",
    "analyzer= CountVectorizer().build_analyzer() \n",
    "def stemmed_words(doc): \n",
    "    return (stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=price['text']\n",
    "text[10]\n",
    "def clean_text(review):\n",
    "    letter_only=re.sub(\"[^a-zA-Z]\",\" \",review)\n",
    "    letter_only=letter_only.lower()\n",
    "    words=letter_only.split()\n",
    "    sw=stopwords.words('english')\n",
    "    words=[w for w in words if w not in sw]\n",
    "    clean=\" \".join(words)\n",
    "    return clean\n",
    "\n",
    "cleaned=[clean_text(i) for i in text]\n",
    "\n",
    "vecterizor=TfidfVectorizer(token_pattern='[a-z]{3,15}')\n",
    "matrix_TF=vecterizor.fit_transform(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9998, 1000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=matrix_TF\n",
    "y=price['price']\n",
    "X_new = SelectKBest(chi2, k=1000).fit_transform(x, y)\n",
    "X_new.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 992.7657 KNN MSE: 906.465 PRE: 0.0869\n",
      "Baseline MSE: 1423.8537 KNN MSE: 1320.8562 PRE: 0.0723\n",
      "Baseline MSE: 1869.8584 KNN MSE: 1766.2627 PRE: 0.0554\n",
      "Baseline MSE: 1129.1042 KNN MSE: 1029.4719 PRE: 0.0882\n",
      "Baseline MSE: 2040.7538 KNN MSE: 1907.9898 PRE: 0.0651\n",
      "Baseline MSE: 1641.2034 KNN MSE: 1538.19 PRE: 0.0628\n",
      "Baseline MSE: 2327.3217 KNN MSE: 2225.4716 PRE: 0.0438\n",
      "Baseline MSE: 1819.8309 KNN MSE: 1647.5951 PRE: 0.0946\n",
      "Baseline MSE: 1364.0498 KNN MSE: 1281.5501 PRE: 0.0605\n",
      "Baseline MSE: 1579.2404 KNN MSE: 1505.451 PRE: 0.0467\n",
      "Overall PRE over 10 trials: 0.06763458034836624\n"
     ]
    }
   ],
   "source": [
    "overall=sum([Knn_estimator(X_new,y,n_neigh=9) for i in range(10)])/10\n",
    "print(\"Overall PRE over 10 trials:\",overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model():\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "    x_std=scaler.fit_transform(X_new)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_std, y, test_size=0.3)\n",
    "\n",
    "    model=Sequential()\n",
    "    model.add(Dense(1000,input_dim=1000,activation='relu',kernel_initializer='normal'))\n",
    "    model.add(Dense(300,input_dim=1000,activation='relu',kernel_initializer='normal'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(Adam(lr=0.001),loss='mean_squared_error',metrics=['mse'])\n",
    "    history=model.fit(X_train,y_train,batch_size=200,epochs=50,validation_split=0.1,verbose=0)\n",
    "\n",
    "    pred=model.predict(X_test)\n",
    "    pred_with_mean=[sum(y_test)/len(y_test)]*len(y_test)\n",
    "    baseline=mean_squared_error(y_test,pred_with_mean)\n",
    "    pred_mse=mean_squared_error(list(y_test),pred)    \n",
    "    r_square=(baseline-pred_mse)/baseline\n",
    "    print(\"Baseline MSE:\",round(baseline,4),\"Keras MSE:\",round(pred_mse,4),\"PRE:\",round(r_square,4))\n",
    "    return r_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code works, take time to run\n",
    "#overall=sum([keras_model() for i in range(10)])/10\n",
    "#print(\"Overall PRE over 10 trials:\",overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parkinson dataset\n",
    "## KNN: 63%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "parkinson=pd.read_csv('C:/Users/zhenguo/Desktop/STA141C/parkinsons_updrs.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 116.8036 KNN MSE: 41.6373 PRE: 0.6435\n",
      "Baseline MSE: 116.7677 KNN MSE: 40.7814 PRE: 0.6507\n",
      "Baseline MSE: 113.2802 KNN MSE: 42.775 PRE: 0.6224\n",
      "Baseline MSE: 112.6663 KNN MSE: 41.4371 PRE: 0.6322\n",
      "Baseline MSE: 115.572 KNN MSE: 43.4973 PRE: 0.6236\n",
      "Baseline MSE: 117.2201 KNN MSE: 41.3375 PRE: 0.6474\n",
      "Baseline MSE: 112.6452 KNN MSE: 43.6306 PRE: 0.6127\n",
      "Baseline MSE: 115.0374 KNN MSE: 44.4435 PRE: 0.6137\n",
      "Baseline MSE: 119.3836 KNN MSE: 43.9502 PRE: 0.6319\n",
      "Baseline MSE: 112.2652 KNN MSE: 42.4233 PRE: 0.6221\n",
      "Overall PRE over 10 trials: 0.6300176987782858\n"
     ]
    }
   ],
   "source": [
    "y=parkinson['total_UPDRS']\n",
    "x=parkinson.drop(['subject#','total_UPDRS','motor_UPDRS'],axis=1) #drop correlated variable and subjectID \n",
    "\n",
    "overall=sum([Knn_estimator(x,y,n_neigh=4) for i in range(10)])/10\n",
    "print(\"Overall PRE over 10 trials:\",overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model():\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "    x_std=scaler.fit_transform(x)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_std, y, test_size=0.3)\n",
    "\n",
    "    model=Sequential()\n",
    "    model.add(Dense(19,input_dim=19,activation='sigmoid',kernel_initializer='normal'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(Adam(lr=0.01),loss='mean_squared_error',metrics=['mse'])\n",
    "    history=model.fit(X_train,y_train,batch_size=20,epochs=100,validation_split=0.1,verbose=0)\n",
    "\n",
    "    pred=model.predict(X_test)\n",
    "    pred_with_mean=[sum(y_test)/len(y_test)]*len(y_test)\n",
    "    baseline=mean_squared_error(y_test,pred_with_mean)\n",
    "    pred_mse=mean_squared_error(list(y_test),pred)    \n",
    "    r_square=(baseline-pred_mse)/baseline\n",
    "    print(\"Baseline MSE:\",round(baseline,4),\"Keras MSE:\",round(pred_mse,4),\"PRE:\",round(r_square,4))\n",
    "    return r_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 120.0527 Keras MSE: 66.045 PRE: 0.4499\n",
      "Baseline MSE: 114.5761 Keras MSE: 65.3685 PRE: 0.4295\n",
      "Baseline MSE: 115.9442 Keras MSE: 64.333 PRE: 0.4451\n",
      "Baseline MSE: 108.0987 Keras MSE: 60.6223 PRE: 0.4392\n",
      "Baseline MSE: 113.7759 Keras MSE: 62.7369 PRE: 0.4486\n",
      "Baseline MSE: 113.4425 Keras MSE: 64.5762 PRE: 0.4308\n",
      "Baseline MSE: 113.5674 Keras MSE: 73.3118 PRE: 0.3545\n",
      "Baseline MSE: 111.404 Keras MSE: 67.4098 PRE: 0.3949\n",
      "Baseline MSE: 115.5393 Keras MSE: 66.7562 PRE: 0.4222\n",
      "Baseline MSE: 117.3396 Keras MSE: 63.0667 PRE: 0.4625\n",
      "Overall PRE over 10 trials: 0.4277145193457866\n"
     ]
    }
   ],
   "source": [
    "#code works,takes time to run 42%~\n",
    "overall=sum([keras_model() for i in range(10)])/10\n",
    "print(\"Overall PRE over 10 trials:\",overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary for `Mercedes`:**\n",
    "* Dataset characteristics: medium scale, low dimension.\n",
    "**Result:**\n",
    "*  KNN(63%) faster run time\n",
    "*  Neural network(42%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Song prediction:\n",
    "\n",
    "*  When we see this vast amount of sample size it appears that KNN is not appropriate since it calculates the distance of all the data points between the training data and test data.The native KNN will generate a distance matrix of approximate 500k * 500k which is very computationally expensive takes too long to run and the other built in KNN algorithms('brute force',ball tree','kd_tree') lead to error.\n",
    "\n",
    "*  What I tried below is to randomly sample 5% of the data from the original dataset, run KNN on the subset of the data, repeat this process for 10 times and compute the average reduction in error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "song=pd.read_csv('C:/Users/zhenguo/Desktop/STA141C/YearPredictionMSD.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=song.iloc[:,0]\n",
    "x=song.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_sample():\n",
    "    rand=song.sample(frac=0.05,replace=True)\n",
    "    y=rand.iloc[:,0]\n",
    "    x=rand.iloc[:,1:]\n",
    "    Knn_estimator(x,y,algo='ball_tree')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 119.9981 KNN MSE: 99.0966 PRE: 0.1742\n",
      "Baseline MSE: 120.8378 KNN MSE: 103.838 PRE: 0.1407\n",
      "Baseline MSE: 116.4953 KNN MSE: 98.3594 PRE: 0.1557\n",
      "Baseline MSE: 125.5185 KNN MSE: 105.2531 PRE: 0.1615\n",
      "Baseline MSE: 122.2611 KNN MSE: 102.0804 PRE: 0.1651\n",
      "Baseline MSE: 118.0886 KNN MSE: 97.1058 PRE: 0.1777\n",
      "Baseline MSE: 120.4048 KNN MSE: 100.2495 PRE: 0.1674\n",
      "Baseline MSE: 126.6178 KNN MSE: 104.6845 PRE: 0.1732\n",
      "Baseline MSE: 121.5631 KNN MSE: 97.55 PRE: 0.1975\n",
      "Baseline MSE: 119.7318 KNN MSE: 101.7491 PRE: 0.1502\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-231-7d5e132512e0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moverall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mone_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Average PRE over 10 random sampling:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moverall\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "overall=sum([one_sample() for i in range(10)])/10\n",
    "print(\"Average PRE over 10 random sampling:\",overall)\n",
    "#0.16632"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model():\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "    x_std=scaler.fit_transform(x)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_std, y, test_size=0.3)\n",
    "\n",
    "    model=Sequential()\n",
    "    model.add(Dense(90,input_dim=90,activation='relu',kernel_initializer='normal'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(Adam(lr=0.001),loss='mean_squared_error',metrics=['mse'])\n",
    "    history=model.fit(X_train,y_train,batch_size=100,epochs=200,validation_split=0.1,verbose=2)\n",
    "\n",
    "    pred=model.predict(X_test)\n",
    "    pred_with_mean=[sum(y_test)/len(y_test)]*len(y_test)\n",
    "    baseline=mean_squared_error(y_test,pred_with_mean)\n",
    "    pred_mse=mean_squared_error(list(y_test),pred)    \n",
    "    r_square=(baseline-pred_mse)/baseline\n",
    "    print(\"Baseline MSE:\",round(baseline,4),\"Keras MSE:\",round(pred_mse,4),\"PRE:\",round(r_square,4))\n",
    "    return r_square\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 324666 samples, validate on 36075 samples\n",
      "Epoch 1/200\n",
      " - 81s - loss: 509861.8214 - mean_squared_error: 509861.8214 - val_loss: 22750.9029 - val_mean_squared_error: 22750.9029\n",
      "Epoch 2/200\n",
      " - 20s - loss: 16102.1918 - mean_squared_error: 16102.1918 - val_loss: 12957.1316 - val_mean_squared_error: 12957.1316\n",
      "Epoch 3/200\n",
      " - 19s - loss: 11045.2747 - mean_squared_error: 11045.2747 - val_loss: 9044.3250 - val_mean_squared_error: 9044.3250\n",
      "Epoch 4/200\n",
      " - 19s - loss: 7268.4593 - mean_squared_error: 7268.4593 - val_loss: 5498.2535 - val_mean_squared_error: 5498.2535\n",
      "Epoch 5/200\n",
      " - 19s - loss: 4069.3904 - mean_squared_error: 4069.3904 - val_loss: 2701.7978 - val_mean_squared_error: 2701.7978\n",
      "Epoch 6/200\n",
      " - 20s - loss: 1722.1742 - mean_squared_error: 1722.1742 - val_loss: 869.2433 - val_mean_squared_error: 869.2433\n",
      "Epoch 7/200\n",
      " - 19s - loss: 495.3708 - mean_squared_error: 495.3708 - val_loss: 208.1331 - val_mean_squared_error: 208.1331\n",
      "Epoch 8/200\n",
      " - 19s - loss: 151.3083 - mean_squared_error: 151.3083 - val_loss: 102.6347 - val_mean_squared_error: 102.6347\n",
      "Epoch 9/200\n",
      " - 19s - loss: 119.8908 - mean_squared_error: 119.8908 - val_loss: 118.4891 - val_mean_squared_error: 118.4891\n",
      "Epoch 10/200\n",
      " - 19s - loss: 115.3601 - mean_squared_error: 115.3601 - val_loss: 100.6497 - val_mean_squared_error: 100.6497\n",
      "Epoch 11/200\n",
      " - 19s - loss: 113.3137 - mean_squared_error: 113.3137 - val_loss: 99.4387 - val_mean_squared_error: 99.4387\n",
      "Epoch 12/200\n",
      " - 19s - loss: 110.8360 - mean_squared_error: 110.8360 - val_loss: 101.0267 - val_mean_squared_error: 101.0267\n",
      "Epoch 13/200\n",
      " - 19s - loss: 109.4337 - mean_squared_error: 109.4337 - val_loss: 107.5255 - val_mean_squared_error: 107.5255\n",
      "Epoch 14/200\n",
      " - 19s - loss: 109.0318 - mean_squared_error: 109.0318 - val_loss: 98.4752 - val_mean_squared_error: 98.4752\n",
      "Epoch 15/200\n",
      " - 19s - loss: 106.6722 - mean_squared_error: 106.6722 - val_loss: 115.3198 - val_mean_squared_error: 115.3198\n",
      "Epoch 16/200\n",
      " - 20s - loss: 107.1268 - mean_squared_error: 107.1268 - val_loss: 100.1249 - val_mean_squared_error: 100.1249\n",
      "Epoch 17/200\n",
      " - 18s - loss: 105.8490 - mean_squared_error: 105.8490 - val_loss: 104.7504 - val_mean_squared_error: 104.7504\n",
      "Epoch 18/200\n",
      " - 18s - loss: 104.6176 - mean_squared_error: 104.6176 - val_loss: 108.1819 - val_mean_squared_error: 108.1819\n",
      "Epoch 19/200\n",
      " - 19s - loss: 104.5998 - mean_squared_error: 104.5998 - val_loss: 104.0256 - val_mean_squared_error: 104.0256\n",
      "Epoch 20/200\n",
      " - 19s - loss: 104.4489 - mean_squared_error: 104.4489 - val_loss: 93.7610 - val_mean_squared_error: 93.7610\n",
      "Epoch 21/200\n",
      " - 19s - loss: 103.1514 - mean_squared_error: 103.1514 - val_loss: 95.9970 - val_mean_squared_error: 95.9970\n",
      "Epoch 22/200\n",
      " - 18s - loss: 104.4835 - mean_squared_error: 104.4835 - val_loss: 100.6049 - val_mean_squared_error: 100.6049\n",
      "Epoch 23/200\n",
      " - 19s - loss: 103.7160 - mean_squared_error: 103.7160 - val_loss: 99.2422 - val_mean_squared_error: 99.2422\n",
      "Epoch 24/200\n",
      " - 18s - loss: 103.0895 - mean_squared_error: 103.0895 - val_loss: 97.5118 - val_mean_squared_error: 97.5118\n",
      "Epoch 25/200\n",
      " - 18s - loss: 103.3938 - mean_squared_error: 103.3938 - val_loss: 100.2639 - val_mean_squared_error: 100.2639\n",
      "Epoch 26/200\n",
      " - 19s - loss: 103.4436 - mean_squared_error: 103.4436 - val_loss: 97.9993 - val_mean_squared_error: 97.9993\n",
      "Epoch 27/200\n",
      " - 19s - loss: 102.5997 - mean_squared_error: 102.5997 - val_loss: 109.0345 - val_mean_squared_error: 109.0345\n",
      "Epoch 28/200\n",
      " - 18s - loss: 103.0052 - mean_squared_error: 103.0052 - val_loss: 98.2220 - val_mean_squared_error: 98.2220\n",
      "Epoch 29/200\n",
      " - 18s - loss: 103.6085 - mean_squared_error: 103.6085 - val_loss: 96.8781 - val_mean_squared_error: 96.8781\n",
      "Epoch 30/200\n",
      " - 19s - loss: 102.3804 - mean_squared_error: 102.3804 - val_loss: 99.5251 - val_mean_squared_error: 99.5251\n",
      "Epoch 31/200\n",
      " - 19s - loss: 102.4971 - mean_squared_error: 102.4971 - val_loss: 95.7981 - val_mean_squared_error: 95.7981\n",
      "Epoch 32/200\n",
      " - 18s - loss: 102.8356 - mean_squared_error: 102.8356 - val_loss: 98.8435 - val_mean_squared_error: 98.8435\n",
      "Epoch 33/200\n",
      " - 19s - loss: 103.8992 - mean_squared_error: 103.8992 - val_loss: 104.3757 - val_mean_squared_error: 104.3757\n",
      "Epoch 34/200\n",
      " - 19s - loss: 102.6667 - mean_squared_error: 102.6667 - val_loss: 102.2406 - val_mean_squared_error: 102.2406\n",
      "Epoch 35/200\n",
      " - 18s - loss: 102.2756 - mean_squared_error: 102.2756 - val_loss: 106.5522 - val_mean_squared_error: 106.5522\n",
      "Epoch 36/200\n",
      " - 18s - loss: 102.1565 - mean_squared_error: 102.1565 - val_loss: 105.0539 - val_mean_squared_error: 105.0539\n",
      "Epoch 37/200\n",
      " - 19s - loss: 101.2931 - mean_squared_error: 101.2931 - val_loss: 97.4252 - val_mean_squared_error: 97.4252\n",
      "Epoch 38/200\n",
      " - 19s - loss: 102.4975 - mean_squared_error: 102.4975 - val_loss: 94.5254 - val_mean_squared_error: 94.5254\n",
      "Epoch 39/200\n",
      " - 19s - loss: 101.9288 - mean_squared_error: 101.9288 - val_loss: 95.6942 - val_mean_squared_error: 95.6942\n",
      "Epoch 40/200\n",
      " - 18s - loss: 103.1943 - mean_squared_error: 103.1943 - val_loss: 93.1956 - val_mean_squared_error: 93.1956\n",
      "Epoch 41/200\n",
      " - 19s - loss: 101.8915 - mean_squared_error: 101.8915 - val_loss: 100.9564 - val_mean_squared_error: 100.9564\n",
      "Epoch 42/200\n",
      " - 18s - loss: 102.0055 - mean_squared_error: 102.0055 - val_loss: 95.0736 - val_mean_squared_error: 95.0736\n",
      "Epoch 43/200\n",
      " - 19s - loss: 102.3799 - mean_squared_error: 102.3799 - val_loss: 138.1085 - val_mean_squared_error: 138.1085\n",
      "Epoch 44/200\n",
      " - 19s - loss: 101.9868 - mean_squared_error: 101.9868 - val_loss: 101.6420 - val_mean_squared_error: 101.6420\n",
      "Epoch 45/200\n",
      " - 18s - loss: 102.0568 - mean_squared_error: 102.0568 - val_loss: 116.7074 - val_mean_squared_error: 116.7074\n",
      "Epoch 46/200\n",
      " - 18s - loss: 102.1705 - mean_squared_error: 102.1705 - val_loss: 99.1964 - val_mean_squared_error: 99.1964\n",
      "Epoch 47/200\n",
      " - 19s - loss: 101.2487 - mean_squared_error: 101.2487 - val_loss: 96.4102 - val_mean_squared_error: 96.4102\n",
      "Epoch 48/200\n",
      " - 20s - loss: 103.0524 - mean_squared_error: 103.0524 - val_loss: 100.5969 - val_mean_squared_error: 100.5969\n",
      "Epoch 49/200\n",
      " - 19s - loss: 101.4511 - mean_squared_error: 101.4511 - val_loss: 93.6286 - val_mean_squared_error: 93.6286\n",
      "Epoch 50/200\n",
      " - 19s - loss: 102.4176 - mean_squared_error: 102.4176 - val_loss: 114.4911 - val_mean_squared_error: 114.4911\n",
      "Epoch 51/200\n",
      " - 20s - loss: 102.1798 - mean_squared_error: 102.1798 - val_loss: 93.9731 - val_mean_squared_error: 93.9731\n",
      "Epoch 52/200\n",
      " - 19s - loss: 100.5502 - mean_squared_error: 100.5502 - val_loss: 95.4724 - val_mean_squared_error: 95.4724\n",
      "Epoch 53/200\n",
      " - 18s - loss: 101.3339 - mean_squared_error: 101.3339 - val_loss: 106.4699 - val_mean_squared_error: 106.4699\n",
      "Epoch 54/200\n",
      " - 18s - loss: 102.2974 - mean_squared_error: 102.2974 - val_loss: 113.9939 - val_mean_squared_error: 113.9939\n",
      "Epoch 55/200\n",
      " - 19s - loss: 100.8483 - mean_squared_error: 100.8483 - val_loss: 101.4786 - val_mean_squared_error: 101.4786\n",
      "Epoch 56/200\n",
      " - 18s - loss: 101.4714 - mean_squared_error: 101.4714 - val_loss: 117.7324 - val_mean_squared_error: 117.7324\n",
      "Epoch 57/200\n",
      " - 18s - loss: 103.3558 - mean_squared_error: 103.3558 - val_loss: 99.1332 - val_mean_squared_error: 99.1332\n",
      "Epoch 58/200\n",
      " - 19s - loss: 101.3907 - mean_squared_error: 101.3907 - val_loss: 105.4601 - val_mean_squared_error: 105.4601\n",
      "Epoch 59/200\n",
      " - 18s - loss: 101.4715 - mean_squared_error: 101.4715 - val_loss: 94.8401 - val_mean_squared_error: 94.8401\n",
      "Epoch 60/200\n",
      " - 18s - loss: 100.8660 - mean_squared_error: 100.8660 - val_loss: 97.7400 - val_mean_squared_error: 97.7400\n",
      "Epoch 61/200\n",
      " - 18s - loss: 100.9525 - mean_squared_error: 100.9525 - val_loss: 99.9993 - val_mean_squared_error: 99.9993\n",
      "Epoch 62/200\n",
      " - 19s - loss: 101.9363 - mean_squared_error: 101.9363 - val_loss: 105.2233 - val_mean_squared_error: 105.2233\n",
      "Epoch 63/200\n",
      " - 18s - loss: 101.5456 - mean_squared_error: 101.5456 - val_loss: 98.6347 - val_mean_squared_error: 98.6347\n",
      "Epoch 64/200\n",
      " - 18s - loss: 101.7107 - mean_squared_error: 101.7107 - val_loss: 93.6356 - val_mean_squared_error: 93.6356\n",
      "Epoch 65/200\n",
      " - 19s - loss: 101.5034 - mean_squared_error: 101.5034 - val_loss: 101.6850 - val_mean_squared_error: 101.6850\n",
      "Epoch 66/200\n",
      " - 19s - loss: 100.8687 - mean_squared_error: 100.8687 - val_loss: 101.7916 - val_mean_squared_error: 101.7916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/200\n",
      " - 18s - loss: 101.0300 - mean_squared_error: 101.0300 - val_loss: 98.4014 - val_mean_squared_error: 98.4014\n",
      "Epoch 68/200\n",
      " - 18s - loss: 101.9435 - mean_squared_error: 101.9435 - val_loss: 95.2120 - val_mean_squared_error: 95.2120\n",
      "Epoch 69/200\n",
      " - 19s - loss: 101.4305 - mean_squared_error: 101.4305 - val_loss: 96.9483 - val_mean_squared_error: 96.9483\n",
      "Epoch 70/200\n",
      " - 18s - loss: 101.4315 - mean_squared_error: 101.4315 - val_loss: 96.4636 - val_mean_squared_error: 96.4636\n",
      "Epoch 71/200\n",
      " - 18s - loss: 101.3227 - mean_squared_error: 101.3227 - val_loss: 96.6604 - val_mean_squared_error: 96.6604\n",
      "Epoch 72/200\n",
      " - 18s - loss: 101.1861 - mean_squared_error: 101.1861 - val_loss: 98.1527 - val_mean_squared_error: 98.1527\n",
      "Epoch 73/200\n",
      " - 19s - loss: 102.0549 - mean_squared_error: 102.0549 - val_loss: 95.9026 - val_mean_squared_error: 95.9026\n",
      "Epoch 74/200\n",
      " - 18s - loss: 101.7005 - mean_squared_error: 101.7005 - val_loss: 94.4309 - val_mean_squared_error: 94.4309\n",
      "Epoch 75/200\n",
      " - 18s - loss: 101.1090 - mean_squared_error: 101.1090 - val_loss: 100.5936 - val_mean_squared_error: 100.5936\n",
      "Epoch 76/200\n",
      " - 19s - loss: 100.5567 - mean_squared_error: 100.5567 - val_loss: 107.6143 - val_mean_squared_error: 107.6143\n",
      "Epoch 77/200\n",
      " - 18s - loss: 102.2844 - mean_squared_error: 102.2844 - val_loss: 98.4011 - val_mean_squared_error: 98.4011\n",
      "Epoch 78/200\n",
      " - 18s - loss: 101.9323 - mean_squared_error: 101.9323 - val_loss: 96.3608 - val_mean_squared_error: 96.3608\n",
      "Epoch 79/200\n",
      " - 18s - loss: 100.8107 - mean_squared_error: 100.8107 - val_loss: 108.5938 - val_mean_squared_error: 108.5938\n",
      "Epoch 80/200\n",
      " - 19s - loss: 101.1809 - mean_squared_error: 101.1809 - val_loss: 96.8609 - val_mean_squared_error: 96.8609\n",
      "Epoch 81/200\n",
      " - 18s - loss: 100.9227 - mean_squared_error: 100.9227 - val_loss: 106.5901 - val_mean_squared_error: 106.5901\n",
      "Epoch 82/200\n",
      " - 18s - loss: 101.3094 - mean_squared_error: 101.3094 - val_loss: 99.5815 - val_mean_squared_error: 99.5815\n",
      "Epoch 83/200\n",
      " - 19s - loss: 101.7719 - mean_squared_error: 101.7719 - val_loss: 98.9389 - val_mean_squared_error: 98.9389\n",
      "Epoch 84/200\n",
      " - 18s - loss: 101.0083 - mean_squared_error: 101.0083 - val_loss: 99.9729 - val_mean_squared_error: 99.9729\n",
      "Epoch 85/200\n",
      " - 18s - loss: 100.8316 - mean_squared_error: 100.8316 - val_loss: 96.1140 - val_mean_squared_error: 96.1140\n",
      "Epoch 86/200\n",
      " - 18s - loss: 100.6071 - mean_squared_error: 100.6071 - val_loss: 93.1762 - val_mean_squared_error: 93.1762\n",
      "Epoch 87/200\n",
      " - 19s - loss: 100.4699 - mean_squared_error: 100.4699 - val_loss: 101.4435 - val_mean_squared_error: 101.4435\n",
      "Epoch 88/200\n",
      " - 18s - loss: 101.3168 - mean_squared_error: 101.3168 - val_loss: 97.9111 - val_mean_squared_error: 97.9111\n",
      "Epoch 89/200\n",
      " - 18s - loss: 101.3069 - mean_squared_error: 101.3069 - val_loss: 98.7408 - val_mean_squared_error: 98.7408\n",
      "Epoch 90/200\n",
      " - 19s - loss: 101.3632 - mean_squared_error: 101.3632 - val_loss: 92.3983 - val_mean_squared_error: 92.3983\n",
      "Epoch 91/200\n",
      " - 18s - loss: 101.1739 - mean_squared_error: 101.1739 - val_loss: 102.4255 - val_mean_squared_error: 102.4255\n",
      "Epoch 92/200\n",
      " - 18s - loss: 100.9241 - mean_squared_error: 100.9241 - val_loss: 104.2800 - val_mean_squared_error: 104.2800\n",
      "Epoch 93/200\n",
      " - 18s - loss: 101.4268 - mean_squared_error: 101.4268 - val_loss: 101.2833 - val_mean_squared_error: 101.2833\n",
      "Epoch 94/200\n",
      " - 19s - loss: 100.9523 - mean_squared_error: 100.9523 - val_loss: 119.0709 - val_mean_squared_error: 119.0709\n",
      "Epoch 95/200\n",
      " - 18s - loss: 100.9172 - mean_squared_error: 100.9172 - val_loss: 93.1806 - val_mean_squared_error: 93.1806\n",
      "Epoch 96/200\n",
      " - 18s - loss: 100.5892 - mean_squared_error: 100.5892 - val_loss: 99.8943 - val_mean_squared_error: 99.8943\n",
      "Epoch 97/200\n",
      " - 19s - loss: 101.1196 - mean_squared_error: 101.1196 - val_loss: 98.3424 - val_mean_squared_error: 98.3424\n",
      "Epoch 98/200\n",
      " - 19s - loss: 101.2314 - mean_squared_error: 101.2314 - val_loss: 96.8062 - val_mean_squared_error: 96.8062\n",
      "Epoch 99/200\n",
      " - 18s - loss: 102.0077 - mean_squared_error: 102.0077 - val_loss: 103.9485 - val_mean_squared_error: 103.9485\n",
      "Epoch 100/200\n",
      " - 18s - loss: 100.8876 - mean_squared_error: 100.8876 - val_loss: 126.4754 - val_mean_squared_error: 126.4754\n",
      "Epoch 101/200\n",
      " - 19s - loss: 100.3765 - mean_squared_error: 100.3765 - val_loss: 97.1632 - val_mean_squared_error: 97.1632\n",
      "Epoch 102/200\n",
      " - 18s - loss: 100.3113 - mean_squared_error: 100.3113 - val_loss: 93.1324 - val_mean_squared_error: 93.1324\n",
      "Epoch 103/200\n",
      " - 18s - loss: 100.6779 - mean_squared_error: 100.6779 - val_loss: 106.9329 - val_mean_squared_error: 106.9329\n",
      "Epoch 104/200\n",
      " - 18s - loss: 100.6831 - mean_squared_error: 100.6831 - val_loss: 108.0247 - val_mean_squared_error: 108.0247\n",
      "Epoch 105/200\n",
      " - 19s - loss: 100.0583 - mean_squared_error: 100.0583 - val_loss: 105.6547 - val_mean_squared_error: 105.6547\n",
      "Epoch 106/200\n",
      " - 18s - loss: 100.6945 - mean_squared_error: 100.6945 - val_loss: 100.0670 - val_mean_squared_error: 100.0670\n",
      "Epoch 107/200\n",
      " - 18s - loss: 100.7315 - mean_squared_error: 100.7315 - val_loss: 97.1653 - val_mean_squared_error: 97.1653\n",
      "Epoch 108/200\n",
      " - 19s - loss: 100.0739 - mean_squared_error: 100.0739 - val_loss: 94.5366 - val_mean_squared_error: 94.5366\n",
      "Epoch 109/200\n",
      " - 18s - loss: 106.3622 - mean_squared_error: 106.3622 - val_loss: 110.4519 - val_mean_squared_error: 110.4519\n",
      "Epoch 110/200\n",
      " - 18s - loss: 99.2542 - mean_squared_error: 99.2542 - val_loss: 96.8608 - val_mean_squared_error: 96.8608\n",
      "Epoch 111/200\n",
      " - 18s - loss: 100.8495 - mean_squared_error: 100.8495 - val_loss: 98.7169 - val_mean_squared_error: 98.7169\n",
      "Epoch 112/200\n",
      " - 19s - loss: 100.4545 - mean_squared_error: 100.4545 - val_loss: 93.7236 - val_mean_squared_error: 93.7236\n",
      "Epoch 113/200\n",
      " - 20s - loss: 100.5224 - mean_squared_error: 100.5224 - val_loss: 100.0697 - val_mean_squared_error: 100.0697\n",
      "Epoch 114/200\n",
      " - 19s - loss: 101.0447 - mean_squared_error: 101.0447 - val_loss: 94.8548 - val_mean_squared_error: 94.8548\n",
      "Epoch 115/200\n",
      " - 19s - loss: 100.0875 - mean_squared_error: 100.0875 - val_loss: 93.6738 - val_mean_squared_error: 93.6738\n",
      "Epoch 116/200\n",
      " - 18s - loss: 100.5841 - mean_squared_error: 100.5841 - val_loss: 94.7583 - val_mean_squared_error: 94.7583\n",
      "Epoch 117/200\n",
      " - 19s - loss: 100.0246 - mean_squared_error: 100.0246 - val_loss: 95.3852 - val_mean_squared_error: 95.3852\n",
      "Epoch 118/200\n",
      " - 19s - loss: 100.2360 - mean_squared_error: 100.2360 - val_loss: 93.7705 - val_mean_squared_error: 93.7705\n",
      "Epoch 119/200\n",
      " - 19s - loss: 100.0651 - mean_squared_error: 100.0651 - val_loss: 103.6482 - val_mean_squared_error: 103.6482\n",
      "Epoch 120/200\n",
      " - 20s - loss: 99.5922 - mean_squared_error: 99.5922 - val_loss: 97.8316 - val_mean_squared_error: 97.8316\n",
      "Epoch 121/200\n",
      " - 20s - loss: 100.9194 - mean_squared_error: 100.9194 - val_loss: 95.9914 - val_mean_squared_error: 95.9914\n",
      "Epoch 122/200\n",
      " - 19s - loss: 99.5561 - mean_squared_error: 99.5561 - val_loss: 101.2742 - val_mean_squared_error: 101.2742\n",
      "Epoch 123/200\n",
      " - 18s - loss: 100.8153 - mean_squared_error: 100.8153 - val_loss: 94.9160 - val_mean_squared_error: 94.9160\n",
      "Epoch 124/200\n",
      " - 19s - loss: 100.3078 - mean_squared_error: 100.3078 - val_loss: 97.6666 - val_mean_squared_error: 97.6666\n",
      "Epoch 125/200\n",
      " - 18s - loss: 100.1847 - mean_squared_error: 100.1847 - val_loss: 98.8580 - val_mean_squared_error: 98.8580\n",
      "Epoch 126/200\n",
      " - 19s - loss: 99.2106 - mean_squared_error: 99.2106 - val_loss: 97.3061 - val_mean_squared_error: 97.3061\n",
      "Epoch 127/200\n",
      " - 18s - loss: 99.7036 - mean_squared_error: 99.7036 - val_loss: 111.1767 - val_mean_squared_error: 111.1767\n",
      "Epoch 128/200\n",
      " - 18s - loss: 99.9723 - mean_squared_error: 99.9723 - val_loss: 96.6982 - val_mean_squared_error: 96.6982\n",
      "Epoch 129/200\n",
      " - 21s - loss: 99.6767 - mean_squared_error: 99.6767 - val_loss: 115.8942 - val_mean_squared_error: 115.8942\n",
      "Epoch 130/200\n",
      " - 20s - loss: 99.8892 - mean_squared_error: 99.8892 - val_loss: 102.4600 - val_mean_squared_error: 102.4600\n",
      "Epoch 131/200\n",
      " - 19s - loss: 99.2883 - mean_squared_error: 99.2883 - val_loss: 103.2556 - val_mean_squared_error: 103.2556\n",
      "Epoch 132/200\n",
      " - 19s - loss: 99.5157 - mean_squared_error: 99.5157 - val_loss: 96.7102 - val_mean_squared_error: 96.7102\n",
      "Epoch 133/200\n",
      " - 19s - loss: 99.6259 - mean_squared_error: 99.6259 - val_loss: 96.4633 - val_mean_squared_error: 96.4633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/200\n",
      " - 19s - loss: 99.7846 - mean_squared_error: 99.7846 - val_loss: 104.1752 - val_mean_squared_error: 104.1752\n",
      "Epoch 135/200\n",
      " - 18s - loss: 99.6131 - mean_squared_error: 99.6131 - val_loss: 97.0436 - val_mean_squared_error: 97.0436\n",
      "Epoch 136/200\n",
      " - 19s - loss: 99.9967 - mean_squared_error: 99.9967 - val_loss: 96.1783 - val_mean_squared_error: 96.1783\n",
      "Epoch 137/200\n",
      " - 19s - loss: 99.9835 - mean_squared_error: 99.9835 - val_loss: 127.0987 - val_mean_squared_error: 127.0987\n",
      "Epoch 138/200\n",
      " - 19s - loss: 100.0722 - mean_squared_error: 100.0722 - val_loss: 96.2400 - val_mean_squared_error: 96.2400\n",
      "Epoch 139/200\n",
      " - 19s - loss: 99.7273 - mean_squared_error: 99.7273 - val_loss: 102.8657 - val_mean_squared_error: 102.8657\n",
      "Epoch 140/200\n",
      " - 19s - loss: 99.1650 - mean_squared_error: 99.1650 - val_loss: 106.8927 - val_mean_squared_error: 106.8927\n",
      "Epoch 141/200\n",
      " - 19s - loss: 100.3583 - mean_squared_error: 100.3583 - val_loss: 94.6413 - val_mean_squared_error: 94.6413\n",
      "Epoch 142/200\n",
      " - 18s - loss: 99.0470 - mean_squared_error: 99.0470 - val_loss: 95.2423 - val_mean_squared_error: 95.2423\n",
      "Epoch 143/200\n",
      " - 19s - loss: 99.4784 - mean_squared_error: 99.4784 - val_loss: 105.1558 - val_mean_squared_error: 105.1558\n",
      "Epoch 144/200\n",
      " - 18s - loss: 99.2287 - mean_squared_error: 99.2287 - val_loss: 111.5146 - val_mean_squared_error: 111.5146\n",
      "Epoch 145/200\n",
      " - 19s - loss: 99.9073 - mean_squared_error: 99.9073 - val_loss: 96.5696 - val_mean_squared_error: 96.5696\n",
      "Epoch 146/200\n",
      " - 19s - loss: 99.4016 - mean_squared_error: 99.4016 - val_loss: 94.0473 - val_mean_squared_error: 94.0473\n",
      "Epoch 147/200\n",
      " - 19s - loss: 99.2725 - mean_squared_error: 99.2725 - val_loss: 101.9441 - val_mean_squared_error: 101.9441\n",
      "Epoch 148/200\n",
      " - 19s - loss: 100.2937 - mean_squared_error: 100.2937 - val_loss: 109.0905 - val_mean_squared_error: 109.0905\n",
      "Epoch 149/200\n",
      " - 18s - loss: 99.0158 - mean_squared_error: 99.0158 - val_loss: 120.6873 - val_mean_squared_error: 120.6873\n",
      "Epoch 150/200\n",
      " - 19s - loss: 99.7692 - mean_squared_error: 99.7692 - val_loss: 95.3313 - val_mean_squared_error: 95.3313\n",
      "Epoch 151/200\n",
      " - 18s - loss: 99.6528 - mean_squared_error: 99.6528 - val_loss: 97.9039 - val_mean_squared_error: 97.9039\n",
      "Epoch 152/200\n",
      " - 18s - loss: 99.1942 - mean_squared_error: 99.1942 - val_loss: 93.8056 - val_mean_squared_error: 93.8056\n",
      "Epoch 153/200\n",
      " - 18s - loss: 99.2337 - mean_squared_error: 99.2337 - val_loss: 95.2097 - val_mean_squared_error: 95.2097\n",
      "Epoch 154/200\n",
      " - 19s - loss: 99.7147 - mean_squared_error: 99.7147 - val_loss: 93.1589 - val_mean_squared_error: 93.1589\n",
      "Epoch 155/200\n",
      " - 18s - loss: 99.8501 - mean_squared_error: 99.8501 - val_loss: 96.9136 - val_mean_squared_error: 96.9136\n",
      "Epoch 156/200\n",
      " - 18s - loss: 98.4138 - mean_squared_error: 98.4138 - val_loss: 97.2893 - val_mean_squared_error: 97.2893\n",
      "Epoch 157/200\n",
      " - 19s - loss: 98.8088 - mean_squared_error: 98.8088 - val_loss: 96.8641 - val_mean_squared_error: 96.8641\n",
      "Epoch 158/200\n",
      " - 18s - loss: 98.9381 - mean_squared_error: 98.9381 - val_loss: 97.8343 - val_mean_squared_error: 97.8343\n",
      "Epoch 159/200\n",
      " - 18s - loss: 99.8202 - mean_squared_error: 99.8202 - val_loss: 105.4921 - val_mean_squared_error: 105.4921\n",
      "Epoch 160/200\n",
      " - 18s - loss: 99.6144 - mean_squared_error: 99.6144 - val_loss: 101.0986 - val_mean_squared_error: 101.0986\n",
      "Epoch 161/200\n",
      " - 19s - loss: 99.3068 - mean_squared_error: 99.3068 - val_loss: 104.0733 - val_mean_squared_error: 104.0733\n",
      "Epoch 162/200\n",
      " - 18s - loss: 100.7865 - mean_squared_error: 100.7865 - val_loss: 96.4508 - val_mean_squared_error: 96.4508\n",
      "Epoch 163/200\n",
      " - 18s - loss: 98.4290 - mean_squared_error: 98.4290 - val_loss: 92.7020 - val_mean_squared_error: 92.7020\n",
      "Epoch 164/200\n",
      " - 20s - loss: 99.5363 - mean_squared_error: 99.5363 - val_loss: 117.6596 - val_mean_squared_error: 117.6596\n",
      "Epoch 165/200\n",
      " - 18s - loss: 99.4368 - mean_squared_error: 99.4368 - val_loss: 101.1077 - val_mean_squared_error: 101.1077\n",
      "Epoch 166/200\n",
      " - 18s - loss: 99.1479 - mean_squared_error: 99.1479 - val_loss: 112.6863 - val_mean_squared_error: 112.6863\n",
      "Epoch 167/200\n",
      " - 18s - loss: 99.2618 - mean_squared_error: 99.2618 - val_loss: 99.2044 - val_mean_squared_error: 99.2044\n",
      "Epoch 168/200\n",
      " - 19s - loss: 99.4929 - mean_squared_error: 99.4929 - val_loss: 94.4203 - val_mean_squared_error: 94.4203\n",
      "Epoch 169/200\n",
      " - 19s - loss: 99.5566 - mean_squared_error: 99.5566 - val_loss: 95.6506 - val_mean_squared_error: 95.6506\n",
      "Epoch 170/200\n",
      " - 19s - loss: 99.6272 - mean_squared_error: 99.6272 - val_loss: 94.4647 - val_mean_squared_error: 94.4647\n",
      "Epoch 171/200\n",
      " - 19s - loss: 99.0458 - mean_squared_error: 99.0458 - val_loss: 101.2454 - val_mean_squared_error: 101.2454\n",
      "Epoch 172/200\n",
      " - 18s - loss: 98.9755 - mean_squared_error: 98.9755 - val_loss: 97.8728 - val_mean_squared_error: 97.8728\n",
      "Epoch 173/200\n",
      " - 18s - loss: 99.4051 - mean_squared_error: 99.4051 - val_loss: 101.7055 - val_mean_squared_error: 101.7055\n",
      "Epoch 174/200\n",
      " - 19s - loss: 99.9557 - mean_squared_error: 99.9557 - val_loss: 103.8257 - val_mean_squared_error: 103.8257\n",
      "Epoch 175/200\n",
      " - 19s - loss: 99.2075 - mean_squared_error: 99.2075 - val_loss: 93.1927 - val_mean_squared_error: 93.1927\n",
      "Epoch 176/200\n",
      " - 18s - loss: 99.5608 - mean_squared_error: 99.5608 - val_loss: 95.8802 - val_mean_squared_error: 95.8802\n",
      "Epoch 177/200\n",
      " - 19s - loss: 99.2448 - mean_squared_error: 99.2448 - val_loss: 94.1386 - val_mean_squared_error: 94.1386\n",
      "Epoch 178/200\n",
      " - 19s - loss: 98.7403 - mean_squared_error: 98.7403 - val_loss: 94.1615 - val_mean_squared_error: 94.1615\n",
      "Epoch 179/200\n",
      " - 19s - loss: 99.8057 - mean_squared_error: 99.8057 - val_loss: 98.2984 - val_mean_squared_error: 98.2984\n",
      "Epoch 180/200\n",
      " - 19s - loss: 98.6528 - mean_squared_error: 98.6528 - val_loss: 94.1256 - val_mean_squared_error: 94.1256\n",
      "Epoch 181/200\n",
      " - 18s - loss: 99.2217 - mean_squared_error: 99.2217 - val_loss: 94.8324 - val_mean_squared_error: 94.8324\n",
      "Epoch 182/200\n",
      " - 19s - loss: 99.1787 - mean_squared_error: 99.1787 - val_loss: 99.7108 - val_mean_squared_error: 99.7108\n",
      "Epoch 183/200\n",
      " - 18s - loss: 99.3623 - mean_squared_error: 99.3623 - val_loss: 96.2642 - val_mean_squared_error: 96.2642\n",
      "Epoch 184/200\n",
      " - 19s - loss: 98.8472 - mean_squared_error: 98.8472 - val_loss: 112.8903 - val_mean_squared_error: 112.8903\n",
      "Epoch 185/200\n",
      " - 20s - loss: 98.8649 - mean_squared_error: 98.8649 - val_loss: 96.8868 - val_mean_squared_error: 96.8868\n",
      "Epoch 186/200\n",
      " - 19s - loss: 99.0781 - mean_squared_error: 99.0781 - val_loss: 96.6026 - val_mean_squared_error: 96.6026\n",
      "Epoch 187/200\n",
      " - 18s - loss: 97.9872 - mean_squared_error: 97.9872 - val_loss: 97.7971 - val_mean_squared_error: 97.7971\n",
      "Epoch 188/200\n",
      " - 18s - loss: 99.2078 - mean_squared_error: 99.2078 - val_loss: 93.9950 - val_mean_squared_error: 93.9950\n",
      "Epoch 189/200\n",
      " - 19s - loss: 99.3596 - mean_squared_error: 99.3596 - val_loss: 96.7860 - val_mean_squared_error: 96.7860\n",
      "Epoch 190/200\n",
      " - 19s - loss: 98.7083 - mean_squared_error: 98.7083 - val_loss: 96.4184 - val_mean_squared_error: 96.4184\n",
      "Epoch 191/200\n",
      " - 19s - loss: 99.1068 - mean_squared_error: 99.1068 - val_loss: 98.3015 - val_mean_squared_error: 98.3015\n",
      "Epoch 192/200\n",
      " - 19s - loss: 98.8130 - mean_squared_error: 98.8130 - val_loss: 97.6180 - val_mean_squared_error: 97.6180\n",
      "Epoch 193/200\n",
      " - 19s - loss: 99.0996 - mean_squared_error: 99.0996 - val_loss: 110.4634 - val_mean_squared_error: 110.4634\n",
      "Epoch 194/200\n",
      " - 18s - loss: 99.1452 - mean_squared_error: 99.1452 - val_loss: 95.0322 - val_mean_squared_error: 95.0322\n",
      "Epoch 195/200\n",
      " - 19s - loss: 98.6967 - mean_squared_error: 98.6967 - val_loss: 95.2290 - val_mean_squared_error: 95.2290\n",
      "Epoch 196/200\n",
      " - 19s - loss: 98.5249 - mean_squared_error: 98.5249 - val_loss: 108.0603 - val_mean_squared_error: 108.0603\n",
      "Epoch 197/200\n",
      " - 18s - loss: 98.0817 - mean_squared_error: 98.0817 - val_loss: 94.4727 - val_mean_squared_error: 94.4727\n",
      "Epoch 198/200\n",
      " - 19s - loss: 98.9747 - mean_squared_error: 98.9747 - val_loss: 98.7348 - val_mean_squared_error: 98.7348\n",
      "Epoch 199/200\n",
      " - 19s - loss: 98.4826 - mean_squared_error: 98.4826 - val_loss: 91.8192 - val_mean_squared_error: 91.8192\n",
      "Epoch 200/200\n",
      " - 19s - loss: 99.0886 - mean_squared_error: 99.0886 - val_loss: 115.4759 - val_mean_squared_error: 115.4759\n",
      "Baseline MSE: 119.6298 Keras MSE: 118.1466 PRE: 0.0124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time used to run the code once: 3878.1280975341797 sec.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t0=time.time()\n",
    "keras_model()\n",
    "t1=time.time()\n",
    "print(\"Time used to run the code once:\",t1-t0,\"sec.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solar Flares\n",
    "## KNN: ~1% reduction in error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 0.0611 KNN MSE: 0.0521 PRE: 0.1468\n",
      "Baseline MSE: 0.1218 KNN MSE: 0.1175 PRE: 0.0356\n",
      "Baseline MSE: 0.1613 KNN MSE: 0.1615 PRE: -0.0011\n",
      "Baseline MSE: 0.2095 KNN MSE: 0.199 PRE: 0.0502\n",
      "Baseline MSE: 0.1253 KNN MSE: 0.135 PRE: -0.0774\n",
      "Baseline MSE: 0.0577 KNN MSE: 0.0655 PRE: -0.1347\n",
      "Baseline MSE: 0.0548 KNN MSE: 0.0605 PRE: -0.1031\n",
      "Baseline MSE: 0.1406 KNN MSE: 0.1311 PRE: 0.0673\n",
      "Baseline MSE: 0.0461 KNN MSE: 0.1029 PRE: -1.2323\n",
      "Baseline MSE: 0.0975 KNN MSE: 0.0972 PRE: 0.0026\n",
      "Overall PRE over 10 trials: -0.12462172487951421\n"
     ]
    }
   ],
   "source": [
    "solar=pd.read_csv(\"C:/Users/zhenguo/Desktop/flare.data2\",sep=\" \")\n",
    "x=solar.iloc[:,1:6]\n",
    "y=solar.iloc[:,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 0.0572 KNN MSE: 0.0547 PRE: 0.0432\n",
      "Baseline MSE: 0.1343 KNN MSE: 0.1371 PRE: -0.0209\n",
      "Baseline MSE: 0.1253 KNN MSE: 0.1209 PRE: 0.0353\n",
      "Baseline MSE: 0.114 KNN MSE: 0.1096 PRE: 0.0386\n",
      "Baseline MSE: 0.1586 KNN MSE: 0.1565 PRE: 0.0132\n",
      "Baseline MSE: 0.1246 KNN MSE: 0.1233 PRE: 0.0105\n",
      "Baseline MSE: 0.0394 KNN MSE: 0.0384 PRE: 0.0257\n",
      "Baseline MSE: 0.0543 KNN MSE: 0.0514 PRE: 0.0548\n",
      "Baseline MSE: 0.0273 KNN MSE: 0.0286 PRE: -0.0449\n",
      "Baseline MSE: 0.0822 KNN MSE: 0.0856 PRE: -0.042\n",
      "Baseline MSE: 0.0611 KNN MSE: 0.0627 PRE: -0.0259\n",
      "Baseline MSE: 0.0702 KNN MSE: 0.0687 PRE: 0.0215\n",
      "Baseline MSE: 0.1503 KNN MSE: 0.1549 PRE: -0.0304\n",
      "Baseline MSE: 0.0878 KNN MSE: 0.0842 PRE: 0.041\n",
      "Baseline MSE: 0.0884 KNN MSE: 0.0921 PRE: -0.041\n",
      "Baseline MSE: 0.1086 KNN MSE: 0.1053 PRE: 0.0301\n",
      "Baseline MSE: 0.1453 KNN MSE: 0.1395 PRE: 0.0396\n",
      "Baseline MSE: 0.0765 KNN MSE: 0.0793 PRE: -0.0369\n",
      "Baseline MSE: 0.0184 KNN MSE: 0.0162 PRE: 0.1175\n",
      "Baseline MSE: 0.0273 KNN MSE: 0.0273 PRE: 0.0008\n",
      "Baseline MSE: 0.0543 KNN MSE: 0.0578 PRE: -0.063\n",
      "Baseline MSE: 0.0553 KNN MSE: 0.0526 PRE: 0.0491\n",
      "Baseline MSE: 0.0461 KNN MSE: 0.0479 PRE: -0.0391\n",
      "Baseline MSE: 0.1048 KNN MSE: 0.1013 PRE: 0.0341\n",
      "Baseline MSE: 0.0941 KNN MSE: 0.0915 PRE: 0.027\n",
      "Baseline MSE: 0.0648 KNN MSE: 0.0645 PRE: 0.005\n",
      "Baseline MSE: 0.0428 KNN MSE: 0.0432 PRE: -0.0088\n",
      "Baseline MSE: 0.064 KNN MSE: 0.059 PRE: 0.077\n",
      "Baseline MSE: 0.0668 KNN MSE: 0.0691 PRE: -0.0332\n",
      "Baseline MSE: 0.1593 KNN MSE: 0.1538 PRE: 0.0348\n",
      "Baseline MSE: 0.1265 KNN MSE: 0.1228 PRE: 0.0294\n",
      "Baseline MSE: 0.1515 KNN MSE: 0.1464 PRE: 0.0339\n",
      "Baseline MSE: 0.0611 KNN MSE: 0.0576 PRE: 0.0575\n",
      "Baseline MSE: 0.0697 KNN MSE: 0.0689 PRE: 0.0117\n",
      "Baseline MSE: 0.1211 KNN MSE: 0.121 PRE: 0.0004\n",
      "Baseline MSE: 0.1496 KNN MSE: 0.1474 PRE: 0.0149\n",
      "Baseline MSE: 0.0788 KNN MSE: 0.0799 PRE: -0.0143\n",
      "Baseline MSE: 0.1475 KNN MSE: 0.1444 PRE: 0.021\n",
      "Baseline MSE: 0.1398 KNN MSE: 0.1371 PRE: 0.0193\n",
      "Baseline MSE: 0.1078 KNN MSE: 0.1068 PRE: 0.0093\n",
      "Baseline MSE: 0.1218 KNN MSE: 0.1163 PRE: 0.0456\n",
      "Baseline MSE: 0.0365 KNN MSE: 0.0346 PRE: 0.0523\n",
      "Baseline MSE: 0.0577 KNN MSE: 0.0534 PRE: 0.0757\n",
      "Baseline MSE: 0.0912 KNN MSE: 0.0871 PRE: 0.045\n",
      "Baseline MSE: 0.0244 KNN MSE: 0.0234 PRE: 0.0385\n",
      "Baseline MSE: 0.0431 KNN MSE: 0.0448 PRE: -0.0398\n",
      "Baseline MSE: 0.0673 KNN MSE: 0.0652 PRE: 0.0323\n",
      "Baseline MSE: 0.0365 KNN MSE: 0.0371 PRE: -0.0148\n",
      "Baseline MSE: 0.1156 KNN MSE: 0.1126 PRE: 0.0257\n",
      "Baseline MSE: 0.1496 KNN MSE: 0.1537 PRE: -0.0273\n",
      "Overall PRE over 50 trials: 0.01457804870015277\n"
     ]
    }
   ],
   "source": [
    "overall=sum([Knn_estimator(x,y,n_neigh=50) for i in range(50)])/50\n",
    "print(\"Overall PRE over 50 trials:\",overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model():\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "    x_std=scaler.fit_transform(x)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_std, y, test_size=0.3)\n",
    "\n",
    "    model=Sequential()\n",
    "    model.add(Dense(5,input_dim=5,activation='sigmoid',kernel_initializer='normal'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(Adam(lr=0.001),loss='mean_squared_error',metrics=['mse'])\n",
    "    history=model.fit(X_train,y_train,batch_size=50,epochs=100,validation_split=0.1,verbose=0)\n",
    "\n",
    "    pred=model.predict(X_test)\n",
    "    pred_with_mean=[sum(y_test)/len(y_test)]*len(y_test)\n",
    "    baseline=mean_squared_error(y_test,pred_with_mean)\n",
    "    pred_mse=mean_squared_error(list(y_test),pred)    \n",
    "    r_square=(baseline-pred_mse)/baseline\n",
    "    print(\"Baseline MSE:\",round(baseline,4),\"Keras MSE:\",round(pred_mse,4),\"PRE:\",round(r_square,4))\n",
    "    return r_square\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras ~1.4%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 0.1003 Keras MSE: 0.0982 PRE: 0.0205\n",
      "Baseline MSE: 0.1836 Keras MSE: 0.1747 PRE: 0.0484\n",
      "Baseline MSE: 0.0306 Keras MSE: 0.0337 PRE: -0.0992\n",
      "Baseline MSE: 0.0481 Keras MSE: 0.0424 PRE: 0.119\n",
      "Baseline MSE: 0.1378 Keras MSE: 0.1441 PRE: -0.0457\n",
      "Baseline MSE: 0.1128 Keras MSE: 0.1055 PRE: 0.0644\n",
      "Baseline MSE: 0.0519 Keras MSE: 0.0491 PRE: 0.0546\n",
      "Baseline MSE: 0.1621 Keras MSE: 0.1531 PRE: 0.0553\n",
      "Baseline MSE: 0.0244 Keras MSE: 0.026 PRE: -0.0683\n",
      "Baseline MSE: 0.1031 Keras MSE: 0.1006 PRE: 0.0238\n",
      "Overall PRE over 10 trials: 0.017286863728540023\n"
     ]
    }
   ],
   "source": [
    "overall=sum([keras_model() for i in range(10)])/10\n",
    "print(\"Overall PRE over 10 trials:\",overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(699, 11)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc=pd.read_csv(\"C:/Users/zhenguo/Desktop/breast-cancer-wisconsin.data\",header=None)\n",
    "bc.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
