{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "\n",
    "The regression algorithms contained in this notebook are K nearest neighbor and neural network(keras).\n",
    "The original data is standardized and then trained with the regressors. \n",
    "\n",
    "\n",
    "**Evaluation metric** The evaluation metric is `PRE(Proportion of reduction in error) or score` which is defined as:\n",
    "$\\frac{SSE_{baseline}-SSE_{regression}}{SSE_{baseline}}$\n",
    "\n",
    "where $SSE_{baseline}$ is the Sum of squared error of estimating with sample mean and $SSE_{regression}$ is the Sum of squared error of estimating with regressor(ie.NN,KNN). The PRE is a the percentage of reduction in error which mostly ranges from 0 to 1. Note that this value could be negative if our model perform worse than using the sample mean.\n",
    "\n",
    "**Missing value**:Impute with mean of the column(for numeric) and the mode of the column(for categorical)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Findings:\n",
    "### KNN: \n",
    "* KNN does not have a model and it does not have the \"training\" part(like neural network). It simply computes a distance matrix of all the data points and choose the neighbor based the distance.It Works relatively well on small to medium dataset.(in both computational time and the amount of reduction in error). However, the main drawback is that when the sample size of the dataset is very large(such as the `song` dataset), computing a distance matrix cannot be accomplished with avalible computational power(ie.computer memory) in reasonable time. In addition, this algorthm also suffers from \"curse of dimensionality\" as we can see for the dataset with relatively high dimension(crime, mercedes,etc), KNN perform less well. \n",
    "\n",
    "### Keras Neural network:\n",
    "\n",
    "*  Main disadvantage for neural network is that it is able to handle dataset with large sample size and high dimensions in reasonable amount of time and the its performance appears to become better as the sample size and dimensionality increase(relatively to KNN), however, the training process can take a very long time. And also because neural network choose initialize the weights of neurons randomly, sometimes they may end up in different local minimum.(which might explain the negative score in the last trial of the `song` dataset.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Graduate admission rate: \n",
    "## KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libaries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use 10 neighbors\n",
    "def Knn_estimator(x,y,n_neigh=10,weights='uniform',algo='auto',p=2):\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "    x_std=scaler.fit_transform(x)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_std, y, test_size=0.3)\n",
    "    \n",
    "    neigh=KNeighborsRegressor(n_neighbors=n_neigh,weights=weights,algorithm=algo,p=p)\n",
    "    neigh.fit(X_train,y_train)\n",
    "\n",
    "    pred_with_mean=[sum(y_test)/len(y_test)]*len(y_test)\n",
    "    baseline=mean_squared_error(y_test,pred_with_mean)\n",
    "    \n",
    "    train_mse=mean_squared_error(list(y_train),neigh.predict(X_train))\n",
    "    pred_mse=mean_squared_error(list(y_test),neigh.predict(X_test))\n",
    "    #r_square=(baseline-pred_mse)/baseline\n",
    "    test_score=r2_score(y_test,neigh.predict(X_test))\n",
    "    train_score=r2_score(y_train,neigh.predict(X_train))\n",
    "    \n",
    "    print(\"Baseline MSE:\",round(baseline,4),\"Testing MSE:\",round(pred_mse,4),\"Test Score(PRE):\",\n",
    "          round(test_score,4),\"Training MSE:\",round(train_mse,4),\"Training Score:\",round(train_score,4))\n",
    "    return test_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 0.0172 Testing MSE: 0.005 Test Score(PRE): 0.7115 Training MSE: 0.0038 Training Score: 0.8227\n",
      "Baseline MSE: 0.0199 Testing MSE: 0.0051 Test Score(PRE): 0.7445 Training MSE: 0.004 Training Score: 0.8051\n",
      "Baseline MSE: 0.0203 Testing MSE: 0.0049 Test Score(PRE): 0.759 Training MSE: 0.0042 Training Score: 0.7919\n",
      "Overall score(PRE) over 3 trials: 0.7383400794062083\n",
      "Average time of running: 0.6186666488647461 sec.\n"
     ]
    }
   ],
   "source": [
    "#import data\n",
    "np.random.seed(0)\n",
    "admission_rate=pd.read_csv('C:/Users/zhenguo/Desktop/STA141C/Admission_Predict.csv')\n",
    "y=admission_rate['Chance of Admit ']\n",
    "x=admission_rate.iloc[:,1:8]\n",
    "\n",
    "t0=time.time()\n",
    "overall=sum([Knn_estimator(x,y) for i in range(3)])/3\n",
    "print(\"Overall score(PRE) over 3 trials:\",overall)\n",
    "t1=time.time()\n",
    "print(\"Average time of running:\",(t1-t0)/3,\"sec.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network(Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhenguo\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use no hidden layers since it is a small dataset, 30 iteration.\n",
    "def keras_model():\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "    x_std=scaler.fit_transform(x)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_std, y, test_size=0.3)\n",
    "    model=Sequential()\n",
    "    model.add(Dense(7,input_dim=7,activation='relu',kernel_initializer='normal'))\n",
    "    model.add(Dense(1,kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "    history=model.fit(X_train,y_train,epochs=30,batch_size=20,validation_split=0.1,verbose=0)\n",
    "    pred=model.predict(X_test)\n",
    "\n",
    "    train_mse=mean_squared_error(list(y_train),model.predict(X_train))\n",
    "    pred_mse=mean_squared_error(list(y_test),pred)\n",
    "    #r_square=(baseline-pred_mse)/baseline\n",
    "    test_score=r2_score(y_test,model.predict(X_test))\n",
    "    train_score=r2_score(y_train,model.predict(X_train))\n",
    "    \n",
    "    pred_with_mean=[sum(y_test)/len(y_test)]*len(y_test)\n",
    "    baseline=mean_squared_error(y_test,pred_with_mean)\n",
    "\n",
    "    print(\"Baseline MSE:\",round(baseline,4),\"Testing MSE:\",round(pred_mse,4),\"Test Score(PRE):\",round(test_score,4),\n",
    "          \"Training MSE:\",round(train_mse,4),\"Training Score:\",round(train_score,4))\n",
    "    return test_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 0.0191 Testing MSE: 0.0076 Test Score(PRE): 0.6018 Training MSE: 0.008 Training Score: 0.6139\n",
      "Baseline MSE: 0.0211 Testing MSE: 0.0097 Test Score(PRE): 0.5433 Training MSE: 0.0078 Training Score: 0.6057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method ScopedTFStatus.__del__ of <tensorflow.python.framework.c_api_util.ScopedTFStatus object at 0x0000019400EF9DA0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\zhenguo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\c_api_util.py\", line 39, in __del__\n",
      "    c_api.TF_DeleteStatus(self.status)\n",
      "AttributeError: 'ScopedTFStatus' object has no attribute 'status'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 0.0206 Testing MSE: 0.0087 Test Score(PRE): 0.5768 Training MSE: 0.008 Training Score: 0.6051\n",
      "Overall Score(PRE) over 3 trials: 0.5739685595143577\n",
      "Average time of running: 55.556661446889244 sec.\n"
     ]
    }
   ],
   "source": [
    "t0=time.time()\n",
    "overall=sum([keras_model() for i in range(3)])/3\n",
    "print(\"Overall Score(PRE) over 3 trials:\",overall)\n",
    "t1=time.time()\n",
    "print(\"Average time of running:\",(t1-t0)/3,\"sec.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary for `Admission`:**\n",
    "* Dataset characteristics: small-scale, low dimension, numeric attributes\n",
    "* Result: KNN(75%) outperforms neural network(57%) in both recduction in error and computational time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Crime incidence in community\n",
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 348761.8031 Testing MSE: 125179.2976 Test Score(PRE): 0.6411 Training MSE: 137352.8568 Training Score: 0.648\n",
      "Baseline MSE: 378456.671 Testing MSE: 164338.6886 Test Score(PRE): 0.5658 Training MSE: 129653.5018 Training Score: 0.656\n",
      "Baseline MSE: 465043.2642 Testing MSE: 196202.7616 Test Score(PRE): 0.5781 Training MSE: 122521.9942 Training Score: 0.6386\n",
      "Overall PRE over 3 trials: 0.5949796993508171\n",
      "Average time of running: 2.5710953871409097 sec.\n"
     ]
    }
   ],
   "source": [
    "crime=pd.read_csv('C:/Users/zhenguo/Desktop/STA141C/Violent_Crime_pred.csv')\n",
    "#subseting the data\n",
    "x=crime.iloc[:,2:-1]\n",
    "y=crime['target']\n",
    "\n",
    "#check the missing valuings in each column\n",
    "#preliminary decision: remove the columns with 1675(over 80%) missing values,to be discussed\n",
    "x.iloc[:,np.sort(x.isna().sum())==0]\n",
    "\n",
    "x=x.dropna(axis='columns')\n",
    "\n",
    "t0=time.time()\n",
    "overall=sum([Knn_estimator(x,y,n_neigh=10) for i in range(3)])/3\n",
    "print(\"Overall PRE over 3 trials:\",overall)\n",
    "t1=time.time()\n",
    "print(\"Average time of running:\",(t1-t0)/3,\"sec.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model():\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "    x_std=scaler.fit_transform(x)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_std, y, test_size=0.3)\n",
    "    model=Sequential()\n",
    "    model.add(Dense(101,input_dim=101,activation='relu',kernel_initializer='normal'))\n",
    "    model.add(Dense(30,input_dim=101,activation='relu',kernel_initializer='normal'))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(Adam(lr=0.001),loss='mean_squared_error',metrics=['mse'])\n",
    "    history=model.fit(X_train,y_train,batch_size=100,epochs=100,validation_split=0.1,verbose=0)\n",
    "    pred=model.predict(X_test)\n",
    "\n",
    "    train_mse=mean_squared_error(list(y_train),model.predict(X_train))\n",
    "    pred_mse=mean_squared_error(list(y_test),pred)\n",
    "    #r_square=(baseline-pred_mse)/baseline\n",
    "    test_score=r2_score(y_test,model.predict(X_test))\n",
    "    train_score=r2_score(y_train,model.predict(X_train))\n",
    "    \n",
    "    pred_with_mean=[sum(y_test)/len(y_test)]*len(y_test)\n",
    "    baseline=mean_squared_error(y_test,pred_with_mean)\n",
    "\n",
    "    print(\"Baseline MSE:\",round(baseline,4),\"Testing MSE:\",round(pred_mse,4),\"Test Score(PRE):\",round(test_score,4),\n",
    "          \"Training MSE:\",round(train_mse,4),\"Training Score:\",round(train_score,4))\n",
    "    return test_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 365370.0568 Testing MSE: 186452.6919 Test Score(PRE): 0.4897 Training MSE: 139215.1094 Training Score: 0.6364\n",
      "Baseline MSE: 413276.6482 Testing MSE: 177959.9205 Test Score(PRE): 0.5694 Training MSE: 122520.8335 Training Score: 0.662\n",
      "Baseline MSE: 380727.5548 Testing MSE: 135213.0401 Test Score(PRE): 0.6449 Training MSE: 133096.8933 Training Score: 0.6465\n",
      "Overall PRE over 3 trials: 0.5679790050541115\n",
      "Average time of running: 29.540505806605022 sec.\n"
     ]
    }
   ],
   "source": [
    "t0=time.time()\n",
    "overall=sum([keras_model() for i in range(3)])/3\n",
    "print(\"Overall PRE over 3 trials:\",overall)\n",
    "t1=time.time()\n",
    "print(\"Average time of running:\",(t1-t0)/3,\"sec.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary for `Crime`:**\n",
    "* Dataset characteristics: Medium-scale, relatively high dimension with irrelavant features, numeric attributes\n",
    "**Result:** \n",
    "*  KNN(58%): faster run time\n",
    "*  Neural network(60%): Takes longer to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Automobile\n",
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhenguo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Cleaning data,process missing values\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import Imputer\n",
    "cars=pd.read_csv('C:/Users/zhenguo/Desktop/STA141C/automobile.csv')\n",
    "cars=cars.replace('?',np.nan).iloc[:,3:] #replace ? with NaN\n",
    "cars['X6'][cars['X6'].isna()]='four' #mode is four, assign four to the missing value\n",
    "impute=Imputer(strategy='mean') #use column mean to impute missing value\n",
    "cars[['X19','X20','X22','X23']]=impute.fit_transform(cars[['X19','X20','X22','X23']])\n",
    "pd.isna(cars).sum() #now no missing values\n",
    "x=cars.iloc[:,0:-1]\n",
    "y=cars.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 63748647.5082 Testing MSE: 6843711.6393 Test Score(PRE): 0.8926 Training MSE: 175952.9571 Training Score: 0.9972\n",
      "Baseline MSE: 58117276.738 Testing MSE: 6470144.8361 Test Score(PRE): 0.8887 Training MSE: 183827.9571 Training Score: 0.9972\n",
      "Baseline MSE: 72659437.792 Testing MSE: 9885418.1967 Test Score(PRE): 0.8639 Training MSE: 122113.6714 Training Score: 0.9979\n",
      "Overall PRE over 3 trials: 0.8817549570219541\n",
      "Average time of running: 0.10473521550496419 sec.\n"
     ]
    }
   ],
   "source": [
    "#get categorical column\n",
    "cate_col=list(x.columns[x.dtypes=='object'])\n",
    "x=pd.get_dummies(x,columns=cate_col) #create dummy variables for the categorical var\n",
    "\n",
    "t0=time.time()\n",
    "overall=sum([Knn_estimator(x,y,n_neigh=1) for i in range(3)])/3\n",
    "print(\"Overall PRE over 3 trials:\",overall)\n",
    "t1=time.time()\n",
    "print(\"Average time of running:\",(t1-t0)/3,\"sec.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model():\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "    x_std=scaler.fit_transform(x)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_std, y, test_size=0.3)\n",
    "    model=Sequential()\n",
    "    model.add(Dense(72,input_dim=72,activation='relu',kernel_initializer='normal'))\n",
    "    model.add(Dense(30,input_dim=72,activation='relu',kernel_initializer='normal'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(Adam(lr=0.01),loss='mean_squared_error',metrics=['mse'])\n",
    "    history=model.fit(X_train,y_train,batch_size=10,epochs=100,validation_split=0.1,verbose=0)\n",
    "    pred=model.predict(X_test)\n",
    "\n",
    "    train_mse=mean_squared_error(list(y_train),model.predict(X_train))\n",
    "    pred_mse=mean_squared_error(list(y_test),pred)\n",
    "    #r_square=(baseline-pred_mse)/baseline\n",
    "    test_score=r2_score(y_test,model.predict(X_test))\n",
    "    train_score=r2_score(y_train,model.predict(X_train))\n",
    "    \n",
    "    pred_with_mean=[sum(y_test)/len(y_test)]*len(y_test)\n",
    "    baseline=mean_squared_error(y_test,pred_with_mean)\n",
    "\n",
    "    print(\"Baseline MSE:\",round(baseline,4),\"Testing MSE:\",round(pred_mse,4),\"Test Score(PRE):\",round(test_score,4),\n",
    "          \"Training MSE:\",round(train_mse,4),\"Training Score:\",round(train_score,4))\n",
    "    return test_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 38007745.0035 Testing MSE: 3376383.6556 Test Score(PRE): 0.9112 Training MSE: 3678298.2118 Training Score: 0.9494\n",
      "Baseline MSE: 61561988.3042 Testing MSE: 7040286.6944 Test Score(PRE): 0.8856 Training MSE: 3074646.8421 Training Score: 0.9515\n",
      "Baseline MSE: 47916909.9629 Testing MSE: 8310035.1433 Test Score(PRE): 0.8266 Training MSE: 3354976.3282 Training Score: 0.9516\n",
      "Overall PRE over 3 trials: 0.8744596756869102\n",
      "Average running time: 22.733724117279053 sec.\n"
     ]
    }
   ],
   "source": [
    "t0=time.time()\n",
    "overall=sum([keras_model() for i in range(3)])/3\n",
    "print(\"Overall PRE over 3 trials:\",overall)\n",
    "t1=time.time()\n",
    "print(\"Average running time:\",(t1-t0)/3,\"sec.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary for `Automobile`:**\n",
    "* Dataset characteristics: small-scale, low dimension, numeric and categorical attributes\n",
    "**Result:**\n",
    "*  KNN(80%)\n",
    "*  Neural network(85%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.Mercedes\n",
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209, 563)"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pass_test=pd.read_csv('C:/Users/zhenguo/Desktop/STA141C/pass_testing.csv')\n",
    "# pass_test.shape #4209 by 378\n",
    "# pd.isna(pass_test).sum().sum() #no missing value\n",
    "\n",
    "x=pass_test.iloc[:,2:]\n",
    "y=pass_test['y']\n",
    "cate_col=list(x.columns[x.dtypes=='object'])\n",
    "x=pd.get_dummies(x,columns=cate_col) #change categorical variables to dummy var\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 163.5831 Testing MSE: 90.7399 Test Score(PRE): 0.4453 Training MSE: 81.8885 Training Score: 0.4866\n",
      "Baseline MSE: 154.1669 Testing MSE: 84.1935 Test Score(PRE): 0.4539 Training MSE: 84.5218 Training Score: 0.4832\n",
      "Baseline MSE: 178.0325 Testing MSE: 106.2395 Test Score(PRE): 0.4033 Training MSE: 74.9296 Training Score: 0.5112\n",
      "Overall PRE over 3 trials: 0.4341454254883413\n",
      "Average running time: 50.60247008005778 sec.\n"
     ]
    }
   ],
   "source": [
    "t0=time.time()\n",
    "overall=sum([Knn_estimator(x,y,n_neigh=20) for i in range(3)])/3\n",
    "print(\"Overall PRE over 3 trials:\",overall)\n",
    "t1=time.time()\n",
    "print(\"Average running time:\",(t1-t0)/3,\"sec.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model():\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "    x_std=scaler.fit_transform(x)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_std, y, test_size=0.3)\n",
    "    model=Sequential()\n",
    "    model.add(Dense(563,input_dim=563,activation='relu',kernel_initializer='normal'))\n",
    "    model.add(Dense(50,input_dim=100,activation='relu',kernel_initializer='normal'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(Adam(lr=0.0001),loss='mean_squared_error',metrics=['mse'])\n",
    "    history=model.fit(X_train,y_train,batch_size=60,epochs=40,validation_split=0.1,verbose=0)\n",
    "    pred=model.predict(X_test)\n",
    "\n",
    "    train_mse=mean_squared_error(list(y_train),model.predict(X_train))\n",
    "    pred_mse=mean_squared_error(list(y_test),pred)\n",
    "    #r_square=(baseline-pred_mse)/baseline\n",
    "    test_score=r2_score(y_test,model.predict(X_test))\n",
    "    train_score=r2_score(y_train,model.predict(X_train))\n",
    "    \n",
    "    pred_with_mean=[sum(y_test)/len(y_test)]*len(y_test)\n",
    "    baseline=mean_squared_error(y_test,pred_with_mean)\n",
    "\n",
    "    print(\"Baseline MSE:\",round(baseline,4),\"Testing MSE:\",round(pred_mse,4),\"Test Score(PRE):\",round(test_score,4),\n",
    "          \"Training MSE:\",round(train_mse,4),\"Training Score:\",round(train_score,4))\n",
    "    return test_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 179.161 Testing MSE: 96.7144 Test Score(PRE): 0.4602 Training MSE: 51.8892 Training Score: 0.6604\n",
      "Baseline MSE: 149.5856 Testing MSE: 70.0858 Test Score(PRE): 0.5315 Training MSE: 62.0418 Training Score: 0.6249\n",
      "Baseline MSE: 147.5254 Testing MSE: 64.8653 Test Score(PRE): 0.5603 Training MSE: 64.8466 Training Score: 0.6103\n",
      "Overall PRE over 3 trials: 0.5173196335544749\n",
      "Average running time: 88.41292119026184 sec.\n"
     ]
    }
   ],
   "source": [
    "t0=time.time()\n",
    "overall=sum([keras_model() for i in range(3)])/3\n",
    "print(\"Overall PRE over 3 trials:\",overall)\n",
    "t1=time.time()\n",
    "print(\"Average running time:\",(t1-t0)/3,\"sec.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary for `Mercedes`:**\n",
    "* Dataset characteristics: medium scale, high dimension, sparse attributes.\n",
    "**Result:**\n",
    "*  KNN(42%)\n",
    "*  Neural network(54%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Parkinson dataset\n",
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "parkinson=pd.read_csv('C:/Users/zhenguo/Desktop/STA141C/parkinsons_updrs.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parkinson.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 112.7311 Testing MSE: 41.7886 Test Score(PRE): 0.6293 Training MSE: 23.7594 Training Score: 0.7938\n",
      "Baseline MSE: 110.4615 Testing MSE: 37.3857 Test Score(PRE): 0.6615 Training MSE: 24.8456 Training Score: 0.7862\n",
      "Baseline MSE: 109.6746 Testing MSE: 43.1917 Test Score(PRE): 0.6062 Training MSE: 24.2849 Training Score: 0.7916\n",
      "Overall PRE over 3 trials: 0.6323467262809421\n",
      "Average running time: 2.6851421197255454 sec.\n"
     ]
    }
   ],
   "source": [
    "y=parkinson['total_UPDRS']\n",
    "x=parkinson.drop(['subject#','total_UPDRS','motor_UPDRS'],axis=1) #drop correlated variable and subjectID \n",
    "\n",
    "t0=time.time()\n",
    "overall=sum([Knn_estimator(x,y,n_neigh=4) for i in range(3)])/3\n",
    "print(\"Overall PRE over 3 trials:\",overall)\n",
    "t1=time.time()\n",
    "print(\"Average running time:\",(t1-t0)/3,\"sec.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model():\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "    x_std=scaler.fit_transform(x)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_std, y, test_size=0.3)\n",
    "    model=Sequential()\n",
    "    model.add(Dense(19,input_dim=19,activation='sigmoid',kernel_initializer='normal'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(Adam(lr=0.01),loss='mean_squared_error',metrics=['mse'])\n",
    "    history=model.fit(X_train,y_train,batch_size=20,epochs=100,validation_split=0.1,verbose=0)\n",
    "\n",
    "    pred=model.predict(X_test)\n",
    "\n",
    "    train_mse=mean_squared_error(list(y_train),model.predict(X_train))\n",
    "    pred_mse=mean_squared_error(list(y_test),pred)\n",
    "    #r_square=(baseline-pred_mse)/baseline\n",
    "    test_score=r2_score(y_test,model.predict(X_test))\n",
    "    train_score=r2_score(y_train,model.predict(X_train))\n",
    "    \n",
    "    pred_with_mean=[sum(y_test)/len(y_test)]*len(y_test)\n",
    "    baseline=mean_squared_error(y_test,pred_with_mean)\n",
    "\n",
    "    print(\"Baseline MSE:\",round(baseline,4),\"Testing MSE:\",round(pred_mse,4),\"Test Score(PRE):\",round(test_score,4),\n",
    "          \"Training MSE:\",round(train_mse,4),\"Training Score:\",round(train_score,4))\n",
    "    return test_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 113.9803 Testing MSE: 58.9867 Test Score(PRE): 0.4825 Training MSE: 57.6232 Training Score: 0.4975\n",
      "Baseline MSE: 115.2662 Testing MSE: 64.7751 Test Score(PRE): 0.438 Training MSE: 58.9313 Training Score: 0.4837\n",
      "Baseline MSE: 118.7042 Testing MSE: 66.2672 Test Score(PRE): 0.4417 Training MSE: 62.3622 Training Score: 0.4462\n",
      "Overall PRE over 10 trials: 0.4540892186819332\n",
      "Average running time: 133.49051674207053 sec.\n"
     ]
    }
   ],
   "source": [
    "#code works,takes time to run 42%~\n",
    "t0=time.time()\n",
    "overall=sum([keras_model() for i in range(3)])/3\n",
    "print(\"Overall PRE over 10 trials:\",overall)\n",
    "t1=time.time()\n",
    "print(\"Average running time:\",(t1-t0)/3,\"sec.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary for `Mercedes`:**\n",
    "* Dataset characteristics: medium scale, low dimension.\n",
    "**Result:**\n",
    "*  KNN(63%) faster run time\n",
    "*  Neural network(42%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.Song prediction:\n",
    "\n",
    "## KNN: Not appropriate for this dataset\n",
    "*  When we see this vast amount of sample size it appears that KNN is not appropriate since it calculates the distance of all the data points between the training data and test data.The native KNN alogrithm will generate a distance matrix of approximate 500k * 500k which is very computationally expensive takes too long(did not finish running in a day) to run and the other built in KNN algorithms('brute force',ball tree','kd_tree') lead to crush.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "song=pd.read_csv('C:/Users/zhenguo/Desktop/STA141C/YearPredictionMSD.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test=song.sample(frac=0.01)\n",
    "y=song.iloc[:,0]\n",
    "x=song.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model():\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "    x_std=scaler.fit_transform(x)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_std, y, test_size=0.3)\n",
    "    model=Sequential()\n",
    "    model.add(Dense(90,input_dim=90,activation='relu',kernel_initializer='normal'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(Adam(lr=0.001),loss='mean_squared_error',metrics=['mse'])\n",
    "    history=model.fit(X_train,y_train,batch_size=100,epochs=15,validation_split=0.1,verbose=2)\n",
    "\n",
    "\n",
    "    pred=model.predict(X_test)\n",
    "\n",
    "    train_mse=mean_squared_error(list(y_train),model.predict(X_train))\n",
    "    pred_mse=mean_squared_error(list(y_test),pred)\n",
    "    #r_square=(baseline-pred_mse)/baseline\n",
    "    test_score=r2_score(y_test,model.predict(X_test))\n",
    "    train_score=r2_score(y_train,model.predict(X_train))\n",
    "    \n",
    "    pred_with_mean=[sum(y_test)/len(y_test)]*len(y_test)\n",
    "    baseline=mean_squared_error(y_test,pred_with_mean)\n",
    "\n",
    "    print(\"Baseline MSE:\",round(baseline,4),\"Testing MSE:\",round(pred_mse,4),\"Test Score(PRE):\",round(test_score,4),\n",
    "          \"Training MSE:\",round(train_mse,4),\"Training Score:\",round(train_score,4))\n",
    "    return test_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 324666 samples, validate on 36075 samples\n",
      "Epoch 1/15\n",
      " - 52s - loss: 568490.2849 - mean_squared_error: 568490.2849 - val_loss: 23190.1720 - val_mean_squared_error: 23190.1720\n",
      "Epoch 2/15\n",
      " - 22s - loss: 16192.3731 - mean_squared_error: 16192.3731 - val_loss: 12803.8490 - val_mean_squared_error: 12803.8490\n",
      "Epoch 3/15\n",
      " - 22s - loss: 10970.7369 - mean_squared_error: 10970.7369 - val_loss: 8944.8871 - val_mean_squared_error: 8944.8871\n",
      "Epoch 4/15\n",
      " - 22s - loss: 7182.0691 - mean_squared_error: 7182.0691 - val_loss: 5223.9855 - val_mean_squared_error: 5223.9855\n",
      "Epoch 5/15\n",
      " - 21s - loss: 3660.1010 - mean_squared_error: 3660.1010 - val_loss: 2221.9598 - val_mean_squared_error: 2221.9598\n",
      "Epoch 6/15\n",
      " - 20s - loss: 1286.7954 - mean_squared_error: 1286.7954 - val_loss: 588.6577 - val_mean_squared_error: 588.6577\n",
      "Epoch 7/15\n",
      " - 22s - loss: 322.1551 - mean_squared_error: 322.1551 - val_loss: 160.9455 - val_mean_squared_error: 160.9455\n",
      "Epoch 8/15\n",
      " - 25s - loss: 134.0348 - mean_squared_error: 134.0348 - val_loss: 113.6266 - val_mean_squared_error: 113.6266\n",
      "Epoch 9/15\n",
      " - 26s - loss: 119.8872 - mean_squared_error: 119.8872 - val_loss: 112.4874 - val_mean_squared_error: 112.4874\n",
      "Epoch 10/15\n",
      " - 22s - loss: 116.2237 - mean_squared_error: 116.2237 - val_loss: 109.1682 - val_mean_squared_error: 109.1682\n",
      "Epoch 11/15\n",
      " - 21s - loss: 113.8820 - mean_squared_error: 113.8820 - val_loss: 126.7563 - val_mean_squared_error: 126.7563\n",
      "Epoch 12/15\n",
      " - 21s - loss: 112.5595 - mean_squared_error: 112.5595 - val_loss: 118.7940 - val_mean_squared_error: 118.7940\n",
      "Epoch 13/15\n",
      " - 22s - loss: 110.7515 - mean_squared_error: 110.7515 - val_loss: 108.3284 - val_mean_squared_error: 108.3284\n",
      "Epoch 14/15\n",
      " - 22s - loss: 110.1387 - mean_squared_error: 110.1387 - val_loss: 100.0596 - val_mean_squared_error: 100.0596\n",
      "Epoch 15/15\n",
      " - 22s - loss: 107.8262 - mean_squared_error: 107.8262 - val_loss: 106.4346 - val_mean_squared_error: 106.4346\n",
      "Baseline MSE: 119.3647 Testing MSE: 106.1438 Test Score(PRE): 0.1108 Training MSE: 107.3645 Training Score: 0.1019\n"
     ]
    }
   ],
   "source": [
    "t0=time.time()\n",
    "keras_model()\n",
    "t1=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 324666 samples, validate on 36075 samples\n",
      "Epoch 1/15\n",
      " - 106s - loss: 528008.2532 - mean_squared_error: 528008.2532 - val_loss: 22935.4314 - val_mean_squared_error: 22935.4314\n",
      "Epoch 2/15\n",
      " - 25s - loss: 16252.9355 - mean_squared_error: 16252.9355 - val_loss: 13076.4931 - val_mean_squared_error: 13076.4931\n",
      "Epoch 3/15\n",
      " - 21s - loss: 11031.8466 - mean_squared_error: 11031.8466 - val_loss: 9293.5219 - val_mean_squared_error: 9293.5219\n",
      "Epoch 4/15\n",
      " - 22s - loss: 7436.1244 - mean_squared_error: 7436.1244 - val_loss: 5885.7071 - val_mean_squared_error: 5885.7071\n",
      "Epoch 5/15\n",
      " - 21s - loss: 4212.7726 - mean_squared_error: 4212.7726 - val_loss: 2880.0413 - val_mean_squared_error: 2880.0413\n",
      "Epoch 6/15\n",
      " - 20s - loss: 1671.6122 - mean_squared_error: 1671.6122 - val_loss: 888.0241 - val_mean_squared_error: 888.0241\n",
      "Epoch 7/15\n",
      " - 19s - loss: 395.8432 - mean_squared_error: 395.8432 - val_loss: 288.9082 - val_mean_squared_error: 288.9082\n",
      "Epoch 8/15\n",
      " - 19s - loss: 130.1714 - mean_squared_error: 130.1714 - val_loss: 206.6611 - val_mean_squared_error: 206.6611\n",
      "Epoch 9/15\n",
      " - 19s - loss: 115.3171 - mean_squared_error: 115.3171 - val_loss: 210.7499 - val_mean_squared_error: 210.7499\n",
      "Epoch 10/15\n",
      " - 18s - loss: 112.3197 - mean_squared_error: 112.3197 - val_loss: 201.0586 - val_mean_squared_error: 201.0586\n",
      "Epoch 11/15\n",
      " - 19s - loss: 109.7169 - mean_squared_error: 109.7169 - val_loss: 200.3284 - val_mean_squared_error: 200.3284\n",
      "Epoch 12/15\n",
      " - 20s - loss: 108.3738 - mean_squared_error: 108.3738 - val_loss: 182.0734 - val_mean_squared_error: 182.0734\n",
      "Epoch 13/15\n",
      " - 19s - loss: 105.0947 - mean_squared_error: 105.0947 - val_loss: 176.1220 - val_mean_squared_error: 176.1220\n",
      "Epoch 14/15\n",
      " - 19s - loss: 105.0617 - mean_squared_error: 105.0617 - val_loss: 193.5816 - val_mean_squared_error: 193.5816\n",
      "Epoch 15/15\n",
      " - 20s - loss: 106.0188 - mean_squared_error: 106.0188 - val_loss: 176.2441 - val_mean_squared_error: 176.2441\n",
      "Baseline MSE: 118.6453 Testing MSE: 101.2077 Test Score(PRE): 0.147 Training MSE: 106.5493 Training Score: 0.111\n"
     ]
    }
   ],
   "source": [
    "t2=time.time()\n",
    "keras_model()\n",
    "t3=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 324666 samples, validate on 36075 samples\n",
      "Epoch 1/15\n",
      " - 150s - loss: 522094.9351 - mean_squared_error: 522094.9351 - val_loss: 22686.8333 - val_mean_squared_error: 22686.8333\n",
      "Epoch 2/15\n",
      " - 22s - loss: 15899.6893 - mean_squared_error: 15899.6893 - val_loss: 12872.1615 - val_mean_squared_error: 12872.1615\n",
      "Epoch 3/15\n",
      " - 22s - loss: 10851.2425 - mean_squared_error: 10851.2425 - val_loss: 8986.1074 - val_mean_squared_error: 8986.1074\n",
      "Epoch 4/15\n",
      " - 22s - loss: 7184.8285 - mean_squared_error: 7184.8285 - val_loss: 5485.5700 - val_mean_squared_error: 5485.5700\n",
      "Epoch 5/15\n",
      " - 23s - loss: 3895.4770 - mean_squared_error: 3895.4770 - val_loss: 2463.4525 - val_mean_squared_error: 2463.4525\n",
      "Epoch 6/15\n",
      " - 22s - loss: 1418.9598 - mean_squared_error: 1418.9598 - val_loss: 682.0889 - val_mean_squared_error: 682.0889\n",
      "Epoch 7/15\n",
      " - 22s - loss: 352.7137 - mean_squared_error: 352.7137 - val_loss: 179.8624 - val_mean_squared_error: 179.8624\n",
      "Epoch 8/15\n",
      " - 23s - loss: 134.7682 - mean_squared_error: 134.7682 - val_loss: 117.0417 - val_mean_squared_error: 117.0417\n",
      "Epoch 9/15\n",
      " - 22s - loss: 113.5542 - mean_squared_error: 113.5542 - val_loss: 114.5102 - val_mean_squared_error: 114.5102\n",
      "Epoch 10/15\n",
      " - 22s - loss: 111.5085 - mean_squared_error: 111.5085 - val_loss: 118.1960 - val_mean_squared_error: 118.1960\n",
      "Epoch 11/15\n",
      " - 22s - loss: 109.6100 - mean_squared_error: 109.6100 - val_loss: 125.5183 - val_mean_squared_error: 125.5183\n",
      "Epoch 12/15\n",
      " - 21s - loss: 109.6788 - mean_squared_error: 109.6788 - val_loss: 112.5564 - val_mean_squared_error: 112.5564\n",
      "Epoch 13/15\n",
      " - 21s - loss: 107.7421 - mean_squared_error: 107.7421 - val_loss: 105.4138 - val_mean_squared_error: 105.4138\n",
      "Epoch 14/15\n",
      " - 21s - loss: 107.7406 - mean_squared_error: 107.7406 - val_loss: 109.7411 - val_mean_squared_error: 109.7411\n",
      "Epoch 15/15\n",
      " - 21s - loss: 106.2197 - mean_squared_error: 106.2197 - val_loss: 116.4019 - val_mean_squared_error: 116.4019\n",
      "Baseline MSE: 117.9544 Testing MSE: 139.6479 Test Score(PRE): -0.1839 Training MSE: 112.575 Training Score: 0.063\n"
     ]
    }
   ],
   "source": [
    "t4=time.time()\n",
    "keras_model()\n",
    "t5=time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged time used to run the code: 631.2542164325714 sec.\n"
     ]
    }
   ],
   "source": [
    "print(\"Averaged time used to run the code:\",(t1-t0+t3-t2+t5-t4)/3,\"sec.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.Solar Flares\n",
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar=pd.read_csv(\"C:/Users/zhenguo/Desktop/flare.data2\",sep=\" \")\n",
    "x=solar.iloc[:,1:6]\n",
    "y=solar.iloc[:,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 0.11 Testing MSE: 0.108 Test Score(PRE): 0.0181 Training MSE: 0.0789 Training Score: 0.0576\n",
      "Baseline MSE: 0.1113 Testing MSE: 0.1079 Test Score(PRE): 0.0303 Training MSE: 0.0797 Training Score: 0.039\n",
      "Baseline MSE: 0.0941 Testing MSE: 0.0898 Test Score(PRE): 0.0456 Training MSE: 0.0881 Training Score: 0.0273\n",
      "Overall PRE over 3 trials: 0.031334725032545495\n",
      "Average running time: 0.4180034001668294 sec.\n"
     ]
    }
   ],
   "source": [
    "t0=time.time()\n",
    "overall=sum([Knn_estimator(x,y,n_neigh=50) for i in range(3)])/3\n",
    "print(\"Overall PRE over 3 trials:\",overall)\n",
    "t1=time.time()\n",
    "print(\"Average running time:\",(t1-t0)/3,\"sec.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "*  performs worse than sample mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model():\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "    x_std=scaler.fit_transform(x)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_std, y, test_size=0.3)\n",
    "    model=Sequential()\n",
    "    model.add(Dense(5,input_dim=5,activation='sigmoid',kernel_initializer='normal'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(Adam(lr=0.001),loss='mean_squared_error',metrics=['mse'])\n",
    "    history=model.fit(X_train,y_train,batch_size=50,epochs=100,validation_split=0.1,verbose=0)\n",
    "    pred=model.predict(X_test)\n",
    "\n",
    "    train_mse=mean_squared_error(list(y_train),model.predict(X_train))\n",
    "    pred_mse=mean_squared_error(list(y_test),pred)\n",
    "    #r_square=(baseline-pred_mse)/baseline\n",
    "    test_score=r2_score(y_test,model.predict(X_test))\n",
    "    train_score=r2_score(y_train,model.predict(X_train))\n",
    "    \n",
    "    pred_with_mean=[sum(y_test)/len(y_test)]*len(y_test)\n",
    "    baseline=mean_squared_error(y_test,pred_with_mean)\n",
    "\n",
    "    print(\"Baseline MSE:\",round(baseline,4),\"Testing MSE:\",round(pred_mse,4),\"Test Score(PRE):\",round(test_score,4),\n",
    "          \"Training MSE:\",round(train_mse,4),\"Training Score:\",round(train_score,4))\n",
    "    return test_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 0.0515 Testing MSE: 0.0537 Test Score(PRE): -0.0437 Training MSE: 0.1032 Training Score: 0.0519\n",
      "Baseline MSE: 0.0878 Testing MSE: 0.0864 Test Score(PRE): 0.0162 Training MSE: 0.09 Training Score: 0.0345\n",
      "Baseline MSE: 0.0273 Testing MSE: 0.0326 Test Score(PRE): -0.1909 Training MSE: 0.1087 Training Score: 0.0866\n",
      "Overall PRE over 10 trials: -0.07277034424293709\n",
      "Average running time: 25.82631508509318 sec.\n"
     ]
    }
   ],
   "source": [
    "t0=time.time()\n",
    "overall=sum([keras_model() for i in range(3)])/3\n",
    "print(\"Overall PRE over 10 trials:\",overall)\n",
    "t1=time.time()\n",
    "print(\"Average running time:\",(t1-t0)/3,\"sec.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.Forest Fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire=pd.read_csv(\"C:/Users/zhenguo/Desktop/forestfires.csv\")\n",
    "y=fire['area']\n",
    "x=fire.drop(['area'],axis=1)\n",
    "\n",
    "cate_col=list(x.columns[x.dtypes=='object'])\n",
    "x=pd.get_dummies(x,columns=cate_col) #change categorical variables to dummy var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## KNN\n",
    " * performs worse than sample mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 8204.8828 Testing MSE: 8341.5585 Test Score(PRE): -0.0167 Training MSE: 2018.6228 Training Score: 0.0958\n",
      "Baseline MSE: 1222.9926 Testing MSE: 1713.6306 Test Score(PRE): -0.4012 Training MSE: 4893.7961 Training Score: 0.0702\n",
      "Baseline MSE: 8522.269 Testing MSE: 8548.0612 Test Score(PRE): -0.003 Training MSE: 1903.3954 Training Score: 0.0885\n",
      "Overall PRE over 3 trials: -0.07277034424293709\n",
      "Average time of running time: 0.08633104960123698 sec.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t0=time.time()\n",
    "Knn_estimatorll=sum([Knn_estimator(x,y,n_neigh=10) for i in range(3)])/3\n",
    "print(\"Overall PRE over 3 trials:\",overall)\n",
    "t1=time.time()\n",
    "print('Average time of running time:',(t1-t0)/3,'sec.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network \n",
    "- performs worse than estimating with sample mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model():\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "    x_std=scaler.fit_transform(x)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_std, y, test_size=0.3)\n",
    "    model=Sequential()\n",
    "    model.add(Dense(29,input_dim=29,activation='sigmoid',kernel_initializer='normal'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(Adam(lr=0.001),loss='mean_squared_error',metrics=['mse'])\n",
    "    history=model.fit(X_train,y_train,batch_size=50,epochs=50,validation_split=0.1,verbose=0)\n",
    "    pred=model.predict(X_test)\n",
    "\n",
    "    train_mse=mean_squared_error(list(y_train),model.predict(X_train))\n",
    "    pred_mse=mean_squared_error(list(y_test),pred)\n",
    "    #r_square=(baseline-pred_mse)/baseline\n",
    "    test_score=r2_score(y_test,model.predict(X_test))\n",
    "    train_score=r2_score(y_train,model.predict(X_train))\n",
    "    \n",
    "    pred_with_mean=[sum(y_test)/len(y_test)]*len(y_test)\n",
    "    baseline=mean_squared_error(y_test,pred_with_mean)\n",
    "\n",
    "    print(\"Baseline MSE:\",round(baseline,4),\"Testing MSE:\",round(pred_mse,4),\"Test Score(PRE):\",round(test_score,4),\n",
    "          \"Training MSE:\",round(train_mse,4),\"Training Score:\",round(train_score,4))\n",
    "    return test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 1374.1884 Testing MSE: 1430.0818 Test Score(PRE): -0.0407 Training MSE: 5267.608 Training Score: -0.0134\n",
      "Baseline MSE: 3788.3997 Testing MSE: 3821.4437 Test Score(PRE): -0.0087 Training MSE: 4211.6425 Training Score: -0.0139\n",
      "Baseline MSE: 1017.9727 Testing MSE: 1026.884 Test Score(PRE): -0.0088 Training MSE: 5382.2354 Training Score: -0.0061\n",
      "Overall PRE over 3 trials: -0.01938338808991606\n",
      "Average time of running time: 16.736035108566284 sec.\n"
     ]
    }
   ],
   "source": [
    "t0=time.time()\n",
    "overall=sum([keras_model() for i in range(3)])/3\n",
    "print(\"Overall PRE over 3 trials:\",overall)\n",
    "t1=time.time()\n",
    "print('Average time of running time:',(t1-t0)/3,'sec.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
