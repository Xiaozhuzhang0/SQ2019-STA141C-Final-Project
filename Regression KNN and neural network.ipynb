{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "\n",
    "*  The regression algorithms contained in this notebook are K nearest neighbor and neural network(keras).\n",
    "*  The original data is standardized and then trained with the regressors. \n",
    "\n",
    "\n",
    "**Evaluation metric** The evaluation metric is `PRE(Proportion of reduction in error)` which is defined as:\n",
    "$\\frac{MSE_{baseline}-MSE_{regression}}{MSE_{baseline}}$\n",
    "\n",
    "where $MSE_{baseline}$ is the Mean squared error of estimating with sample mean and $MSE_{regression}$ is the Mean squared error of estimating with regressor(ie.NN,KNN). The PRE is a the percentage of reduction in error which mostly ranges from 0 to 1.Note that this value could be negative if our model perform worse than using the sample mean.\n",
    "\n",
    "**Missing value**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graduate admission rate: KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libaries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use 10 neighbors\n",
    "def Knn_estimator(x,y,n_neigh=10,weights='uniform',algo='auto',p=2):\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "    x_std=scaler.fit_transform(x)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_std, y, test_size=0.3)\n",
    "    \n",
    "    neigh=KNeighborsRegressor(n_neighbors=n_neigh,weights=weights,algorithm=algo,p=p)\n",
    "    neigh.fit(X_train,y_train)\n",
    "    \n",
    "    pred_with_mean=[sum(y_test)/len(y_test)]*len(y_test)\n",
    "    baseline=mean_squared_error(y_test,pred_with_mean)\n",
    "    \n",
    "    pred_mse=mean_squared_error(list(y_test),neigh.predict(X_test))\n",
    "    r_square=(baseline-pred_mse)/baseline\n",
    "    \n",
    "    print(\"Baseline MSE:\",round(baseline,4),\"KNN MSE:\",round(pred_mse,4),\"PRE:\",round(r_square,4))\n",
    "    return r_square\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 0.0196 KNN MSE: 0.0046 PRE: 0.7651\n",
      "Baseline MSE: 0.0239 KNN MSE: 0.0057 PRE: 0.7638\n",
      "Baseline MSE: 0.0213 KNN MSE: 0.0054 PRE: 0.7467\n",
      "Baseline MSE: 0.025 KNN MSE: 0.0061 PRE: 0.7546\n",
      "Baseline MSE: 0.0194 KNN MSE: 0.0044 PRE: 0.7717\n",
      "Baseline MSE: 0.02 KNN MSE: 0.0064 PRE: 0.68\n",
      "Baseline MSE: 0.0204 KNN MSE: 0.0042 PRE: 0.7942\n",
      "Baseline MSE: 0.0191 KNN MSE: 0.0043 PRE: 0.7739\n",
      "Baseline MSE: 0.0196 KNN MSE: 0.0059 PRE: 0.6991\n",
      "Baseline MSE: 0.0164 KNN MSE: 0.0041 PRE: 0.75\n",
      "Overall PRE over 10 trials: 0.749932411216001\n"
     ]
    }
   ],
   "source": [
    "#import data\n",
    "admission_rate=pd.read_csv('C:/Users/zhenguo/Desktop/STA141C/Admission_Predict.csv')\n",
    "y=admission_rate['Chance of Admit ']\n",
    "x=admission_rate.iloc[:,1:8]\n",
    "\n",
    "overall=sum([Knn_estimator(x,y) for i in range(10)])/10\n",
    "print(\"Overall PRE over 10 trials:\",overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression with Neural Network(Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhenguo\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use no hidden layers since it is a small dataset, 30 iteration.\n",
    "def keras_model():\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_std, y, test_size=0.3)\n",
    "    model=Sequential()\n",
    "    model.add(Dense(7,input_dim=7,activation='relu',kernel_initializer='normal'))\n",
    "    model.add(Dense(1,kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "    history=model.fit(X_train,y_train,epochs=30,validation_split=0.1,verbose=0)\n",
    "    pred=model.predict(X_test)\n",
    "\n",
    "    pred_with_mean=[sum(y_test)/len(y_test)]*len(y_test)\n",
    "    baseline=mean_squared_error(y_test,pred_with_mean)\n",
    "    pred_mse=mean_squared_error(list(y_test),pred)    \n",
    "    r_square=(baseline-pred_mse)/baseline\n",
    "    print(\"Baseline MSE:\",round(baseline,4),\"Keras MSE:\",round(pred_mse,4),\"PRE:\",round(r_square,4))\n",
    "    return r_square\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 0.0214 Keras MSE: 0.0105 PRE: 0.5086\n",
      "Baseline MSE: 0.02 Keras MSE: 0.009 PRE: 0.5482\n",
      "Baseline MSE: 0.017 Keras MSE: 0.0072 PRE: 0.5765\n",
      "Baseline MSE: 0.0193 Keras MSE: 0.0083 PRE: 0.5709\n",
      "Baseline MSE: 0.0186 Keras MSE: 0.0081 PRE: 0.5677\n",
      "Baseline MSE: 0.0182 Keras MSE: 0.0082 PRE: 0.5523\n",
      "Baseline MSE: 0.0218 Keras MSE: 0.0099 PRE: 0.5477\n",
      "Baseline MSE: 0.0196 Keras MSE: 0.01 PRE: 0.4901\n",
      "Baseline MSE: 0.0221 Keras MSE: 0.011 PRE: 0.4997\n",
      "Baseline MSE: 0.0192 Keras MSE: 0.0079 PRE: 0.5918\n",
      "Overall PRE over 10 trials: 0.5453546316152135\n"
     ]
    }
   ],
   "source": [
    "overall=sum([keras_model() for i in range(10)])/10\n",
    "print(\"Overall PRE over 10 trials:\",overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary for this dataset: KNN outperforms neural network with relatively small sample size and low dimension and the computation for KNN is much shorter than neural network. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crime incidence in community\n",
    "### KNN:58% reduction in error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 405784.2056 KNN MSE: 188459.6628 PRE: 0.5356\n",
      "Baseline MSE: 354282.6461 KNN MSE: 150688.9022 PRE: 0.5747\n",
      "Baseline MSE: 386027.6508 KNN MSE: 158331.6898 PRE: 0.5898\n",
      "Baseline MSE: 384972.0335 KNN MSE: 153695.831 PRE: 0.6008\n",
      "Baseline MSE: 454711.4389 KNN MSE: 205837.6454 PRE: 0.5473\n",
      "Baseline MSE: 376035.4971 KNN MSE: 156647.2317 PRE: 0.5834\n",
      "Baseline MSE: 390505.3232 KNN MSE: 152794.9659 PRE: 0.6087\n",
      "Baseline MSE: 340393.6825 KNN MSE: 152998.8462 PRE: 0.5505\n",
      "Baseline MSE: 305672.3447 KNN MSE: 128184.1639 PRE: 0.5806\n",
      "Baseline MSE: 470380.1817 KNN MSE: 208468.2079 PRE: 0.5568\n",
      "Overall PRE over 10 trials: 0.572828950213284\n"
     ]
    }
   ],
   "source": [
    "crime=pd.read_csv('C:/Users/zhenguo/Desktop/STA141C/Violent_Crime_pred.csv')\n",
    "#subseting the data\n",
    "x=crime.iloc[:,2:-1]\n",
    "y=crime['target']\n",
    "\n",
    "#check the missing valuings in each column\n",
    "#preliminary decision: remove the columns with 1675(over 80%) missing values,to be discussed\n",
    "x.iloc[:,np.sort(x.isna().sum())==0]\n",
    "\n",
    "x=x.dropna(axis='columns')\n",
    "\n",
    "\n",
    "overall=sum([Knn_estimator(x,y,n_neigh=10) for i in range(10)])/10\n",
    "print(\"Overall PRE over 10 trials:\",overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network: 60% reduction in error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model():\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "    x_std=scaler.fit_transform(x)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_std, y, test_size=0.3)\n",
    "    model=Sequential()\n",
    "    model.add(Dense(101,input_dim=101,activation='relu',kernel_initializer='normal'))\n",
    "    model.add(Dense(30,input_dim=101,activation='relu',kernel_initializer='normal'))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(Adam(lr=0.001),loss='mean_squared_error',metrics=['mse'])\n",
    "    history=model.fit(X_train,y_train,batch_size=50,epochs=100,validation_split=0.1,verbose=0)\n",
    "    pred=model.predict(X_test)\n",
    "\n",
    "    pred_with_mean=[sum(y_test)/len(y_test)]*len(y_test)\n",
    "    baseline=mean_squared_error(y_test,pred_with_mean)\n",
    "    pred_mse=mean_squared_error(list(y_test),pred)    \n",
    "    r_square=(baseline-pred_mse)/baseline\n",
    "    print(\"Baseline MSE:\",round(baseline,4),\"Keras MSE:\",round(pred_mse,4),\"PRE:\",round(r_square,4))\n",
    "    return r_square\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 399407.9197 Keras MSE: 174416.6583 PRE: 0.5633\n",
      "Baseline MSE: 392564.8185 Keras MSE: 159461.854 PRE: 0.5938\n",
      "Baseline MSE: 374590.9379 Keras MSE: 149265.7801 PRE: 0.6015\n",
      "Baseline MSE: 411878.5184 Keras MSE: 168782.0356 PRE: 0.5902\n",
      "Baseline MSE: 333814.1456 Keras MSE: 126122.4371 PRE: 0.6222\n",
      "Baseline MSE: 373999.8708 Keras MSE: 134377.3122 PRE: 0.6407\n",
      "Baseline MSE: 400469.2474 Keras MSE: 139923.6825 PRE: 0.6506\n",
      "Baseline MSE: 355732.0766 Keras MSE: 137451.6639 PRE: 0.6136\n",
      "Baseline MSE: 315501.8113 Keras MSE: 129092.1408 PRE: 0.5908\n",
      "Baseline MSE: 328360.6527 Keras MSE: 144484.4955 PRE: 0.56\n",
      "Overall PRE over 10 trials: 0.6026751535581809\n"
     ]
    }
   ],
   "source": [
    "overall=sum([keras_model() for i in range(10)])/10\n",
    "print(\"Overall PRE over 10 trials:\",overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automobile: categorical and numerical variables\n",
    "## KNN: 80% reduction in error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhenguo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Cleaning data,process missing values\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import Imputer\n",
    "cars=pd.read_csv('C:/Users/zhenguo/Desktop/STA141C/automobile.csv')\n",
    "cars=cars.replace('?',np.nan).iloc[:,3:] #replace ? with NaN\n",
    "cars['X6'][cars['X6'].isna()]='four' #mode is four, assign four to the missing value\n",
    "impute=Imputer(strategy='mean') #use column mean to impute missing value\n",
    "cars[['X19','X20','X22','X23']]=impute.fit_transform(cars[['X19','X20','X22','X23']])\n",
    "pd.isna(cars).sum() #now no missing values\n",
    "x=cars.iloc[:,0:-1]\n",
    "y=cars.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 69981239.011 KNN MSE: 11444136.4426 PRE: 0.8365\n",
      "Baseline MSE: 81672005.7834 KNN MSE: 14215479.2951 PRE: 0.8259\n",
      "Baseline MSE: 51954682.5477 KNN MSE: 11094325.9344 PRE: 0.7865\n",
      "Baseline MSE: 47282803.7974 KNN MSE: 6081208.7049 PRE: 0.8714\n",
      "Baseline MSE: 51406837.663 KNN MSE: 9430858.1639 PRE: 0.8165\n",
      "Baseline MSE: 75303550.7025 KNN MSE: 5121470.0 PRE: 0.932\n",
      "Baseline MSE: 63408579.3496 KNN MSE: 38669133.8525 PRE: 0.3902\n",
      "Baseline MSE: 71592368.7073 KNN MSE: 10376146.8525 PRE: 0.8551\n",
      "Baseline MSE: 62816203.9307 KNN MSE: 11952412.541 PRE: 0.8097\n",
      "Baseline MSE: 78273393.2959 KNN MSE: 9037491.3934 PRE: 0.8845\n",
      "Overall PRE over 10 trials: 0.8008283461053187\n"
     ]
    }
   ],
   "source": [
    "#get categorical column\n",
    "cate_col=list(x.columns[x.dtypes=='object'])\n",
    "x=pd.get_dummies(x,columns=cate_col) #create dummy variables for the categorical var\n",
    "\n",
    "overall=sum([Knn_estimator(x,y,n_neigh=1) for i in range(10)])/10\n",
    "print(\"Overall PRE over 10 trials:\",overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network\n",
    "## Reduction in error:85%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model():\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "    x_std=scaler.fit_transform(x)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_std, y, test_size=0.3)\n",
    "\n",
    "    model=Sequential()\n",
    "    model.add(Dense(72,input_dim=72,activation='relu',kernel_initializer='normal'))\n",
    "    model.add(Dense(30,input_dim=72,activation='relu',kernel_initializer='normal'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(Adam(lr=0.01),loss='mean_squared_error',metrics=['mse'])\n",
    "    history=model.fit(X_train,y_train,batch_size=10,epochs=100,validation_split=0.1,verbose=0)\n",
    "\n",
    "    pred=model.predict(X_test)\n",
    "    pred_with_mean=[sum(y_test)/len(y_test)]*len(y_test)\n",
    "    baseline=mean_squared_error(y_test,pred_with_mean)\n",
    "    pred_mse=mean_squared_error(list(y_test),pred)    \n",
    "    r_square=(baseline-pred_mse)/baseline\n",
    "    print(\"Baseline MSE:\",round(baseline,4),\"Keras MSE:\",round(pred_mse,4),\"PRE:\",round(r_square,4))\n",
    "    return r_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 51809612.8729 Keras MSE: 12573943.5237 PRE: 0.7573\n",
      "Baseline MSE: 54178137.5243 Keras MSE: 8323390.5802 PRE: 0.8464\n",
      "Baseline MSE: 59519766.9782 Keras MSE: 6269259.7456 PRE: 0.8947\n",
      "Baseline MSE: 55601864.5402 Keras MSE: 4921577.871 PRE: 0.9115\n",
      "Baseline MSE: 87577031.1508 Keras MSE: 11983410.8109 PRE: 0.8632\n",
      "Baseline MSE: 42201287.0314 Keras MSE: 6483283.4757 PRE: 0.8464\n",
      "Baseline MSE: 78607754.738 Keras MSE: 20062081.2037 PRE: 0.7448\n",
      "Baseline MSE: 35341461.3255 Keras MSE: 4332851.3296 PRE: 0.8774\n",
      "Baseline MSE: 63590487.4394 Keras MSE: 7154329.5737 PRE: 0.8875\n",
      "Baseline MSE: 65787990.5751 Keras MSE: 4981221.9195 PRE: 0.9243\n",
      "Overall PRE over 10 trials: 0.8553329174253268\n"
     ]
    }
   ],
   "source": [
    "overall=sum([keras_model() for i in range(10)])/10\n",
    "print(\"Overall PRE over 10 trials:\",overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:High reduction in error probably due to this particular dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mercede: sparse data with binary variables and categorical variables\n",
    "## KNN:42%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4209, 563)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pass_test=pd.read_csv('C:/Users/zhenguo/Desktop/STA141C/pass_testing.csv')\n",
    "# pass_test.shape #4209 by 378\n",
    "# pd.isna(pass_test).sum().sum() #no missing value\n",
    "\n",
    "x=pass_test.iloc[:,2:]\n",
    "y=pass_test['y']\n",
    "cate_col=list(x.columns[x.dtypes=='object'])\n",
    "x=pd.get_dummies(x,columns=cate_col) #change categorical variables to dummy var\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 166.8287 KNN MSE: 99.6932 PRE: 0.4024\n",
      "Baseline MSE: 155.9393 KNN MSE: 86.065 PRE: 0.4481\n",
      "Baseline MSE: 172.868 KNN MSE: 110.6822 PRE: 0.3597\n",
      "Baseline MSE: 178.119 KNN MSE: 108.3273 PRE: 0.3918\n",
      "Baseline MSE: 166.2521 KNN MSE: 92.9012 PRE: 0.4412\n",
      "Baseline MSE: 149.669 KNN MSE: 83.1095 PRE: 0.4447\n",
      "Baseline MSE: 167.5927 KNN MSE: 93.5079 PRE: 0.4421\n",
      "Baseline MSE: 153.6807 KNN MSE: 87.8013 PRE: 0.4287\n",
      "Baseline MSE: 163.8447 KNN MSE: 89.3852 PRE: 0.4545\n",
      "Baseline MSE: 151.655 KNN MSE: 80.0287 PRE: 0.4723\n",
      "Overall PRE over 10 trials: 0.4285458044504349\n"
     ]
    }
   ],
   "source": [
    "overall=sum([Knn_estimator(x,y,n_neigh=20) for i in range(10)])/10\n",
    "print(\"Overall PRE over 10 trials:\",overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network:53%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model():\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "    x_std=scaler.fit_transform(x)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_std, y, test_size=0.3)\n",
    "\n",
    "    model=Sequential()\n",
    "    model.add(Dense(563,input_dim=563,activation='relu',kernel_initializer='normal'))\n",
    "    model.add(Dense(50,input_dim=100,activation='relu',kernel_initializer='normal'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(Adam(lr=0.0001),loss='mean_squared_error',metrics=['mse'])\n",
    "    history=model.fit(X_train,y_train,batch_size=60,epochs=40,validation_split=0.1,verbose=0)\n",
    "\n",
    "    pred=model.predict(X_test)\n",
    "    pred_with_mean=[sum(y_test)/len(y_test)]*len(y_test)\n",
    "    baseline=mean_squared_error(y_test,pred_with_mean)\n",
    "    pred_mse=mean_squared_error(list(y_test),pred)    \n",
    "    r_square=(baseline-pred_mse)/baseline\n",
    "    print(\"Baseline MSE:\",round(baseline,4),\"Keras MSE:\",round(pred_mse,4),\"PRE:\",round(r_square,4))\n",
    "    return r_square\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 154.4703 Keras MSE: 74.9101 PRE: 0.5151\n",
      "Baseline MSE: 157.3397 Keras MSE: 69.7739 PRE: 0.5565\n",
      "Baseline MSE: 162.5573 Keras MSE: 74.1338 PRE: 0.544\n",
      "Baseline MSE: 155.1553 Keras MSE: 73.516 PRE: 0.5262\n",
      "Baseline MSE: 170.2172 Keras MSE: 88.6884 PRE: 0.479\n",
      "Baseline MSE: 159.3436 Keras MSE: 69.6261 PRE: 0.563\n",
      "Baseline MSE: 169.3383 Keras MSE: 83.6642 PRE: 0.5059\n",
      "Baseline MSE: 156.3171 Keras MSE: 70.6824 PRE: 0.5478\n",
      "Baseline MSE: 147.8653 Keras MSE: 65.0646 PRE: 0.56\n",
      "Baseline MSE: 152.6489 Keras MSE: 66.336 PRE: 0.5654\n",
      "Overall PRE over 10 trials: 0.536290524387286\n"
     ]
    }
   ],
   "source": [
    "overall=sum([keras_model() for i in range(10)])/10\n",
    "print(\"Overall PRE over 10 trials:\",overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text data(extra dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "price=pd.read_csv('C:/Users/zhenguo/Desktop/STA141C/price_predict_reduced.csv',encoding='ISO-8859-1')\n",
    "price=price.dropna()\n",
    "import re\n",
    "import nltk\n",
    "#nltk.download()\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem.snowball import FrenchStemmer \n",
    "stemmer =FrenchStemmer() \n",
    "analyzer= CountVectorizer().build_analyzer() \n",
    "def stemmed_words(doc): \n",
    "    return (stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=price['text']\n",
    "text[10]\n",
    "def clean_text(review):\n",
    "    letter_only=re.sub(\"[^a-zA-Z]\",\" \",review)\n",
    "    letter_only=letter_only.lower()\n",
    "    words=letter_only.split()\n",
    "    sw=stopwords.words('english')\n",
    "    words=[w for w in words if w not in sw]\n",
    "    clean=\" \".join(words)\n",
    "    return clean\n",
    "\n",
    "cleaned=[clean_text(i) for i in text]\n",
    "\n",
    "vecterizor=TfidfVectorizer(token_pattern='[a-z]{3,15}')\n",
    "matrix_TF=vecterizor.fit_transform(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9998, 1000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=matrix_TF\n",
    "y=price['price']\n",
    "X_new = SelectKBest(chi2, k=1000).fit_transform(x, y)\n",
    "X_new.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 992.7657 KNN MSE: 906.465 PRE: 0.0869\n",
      "Baseline MSE: 1423.8537 KNN MSE: 1320.8562 PRE: 0.0723\n",
      "Baseline MSE: 1869.8584 KNN MSE: 1766.2627 PRE: 0.0554\n",
      "Baseline MSE: 1129.1042 KNN MSE: 1029.4719 PRE: 0.0882\n",
      "Baseline MSE: 2040.7538 KNN MSE: 1907.9898 PRE: 0.0651\n",
      "Baseline MSE: 1641.2034 KNN MSE: 1538.19 PRE: 0.0628\n",
      "Baseline MSE: 2327.3217 KNN MSE: 2225.4716 PRE: 0.0438\n",
      "Baseline MSE: 1819.8309 KNN MSE: 1647.5951 PRE: 0.0946\n",
      "Baseline MSE: 1364.0498 KNN MSE: 1281.5501 PRE: 0.0605\n",
      "Baseline MSE: 1579.2404 KNN MSE: 1505.451 PRE: 0.0467\n",
      "Overall PRE over 10 trials: 0.06763458034836624\n"
     ]
    }
   ],
   "source": [
    "overall=sum([Knn_estimator(X_new,y,n_neigh=9) for i in range(10)])/10\n",
    "print(\"Overall PRE over 10 trials:\",overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model():\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "    x_std=scaler.fit_transform(X_new)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_std, y, test_size=0.3)\n",
    "\n",
    "    model=Sequential()\n",
    "    model.add(Dense(1000,input_dim=1000,activation='relu',kernel_initializer='normal'))\n",
    "    model.add(Dense(300,input_dim=1000,activation='relu',kernel_initializer='normal'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(Adam(lr=0.001),loss='mean_squared_error',metrics=['mse'])\n",
    "    history=model.fit(X_train,y_train,batch_size=200,epochs=50,validation_split=0.1,verbose=0)\n",
    "\n",
    "    pred=model.predict(X_test)\n",
    "    pred_with_mean=[sum(y_test)/len(y_test)]*len(y_test)\n",
    "    baseline=mean_squared_error(y_test,pred_with_mean)\n",
    "    pred_mse=mean_squared_error(list(y_test),pred)    \n",
    "    r_square=(baseline-pred_mse)/baseline\n",
    "    print(\"Baseline MSE:\",round(baseline,4),\"Keras MSE:\",round(pred_mse,4),\"PRE:\",round(r_square,4))\n",
    "    return r_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code works, take time to run\n",
    "#overall=sum([keras_model() for i in range(10)])/10\n",
    "#print(\"Overall PRE over 10 trials:\",overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parkinson dataset\n",
    "## KNN: 63%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "parkinson=pd.read_csv('C:/Users/zhenguo/Desktop/STA141C/parkinsons_updrs.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 109.1527 KNN MSE: 43.138 PRE: 0.6048\n",
      "Baseline MSE: 114.4242 KNN MSE: 38.3164 PRE: 0.6651\n",
      "Baseline MSE: 111.4891 KNN MSE: 42.2319 PRE: 0.6212\n",
      "Baseline MSE: 109.725 KNN MSE: 39.9393 PRE: 0.636\n",
      "Baseline MSE: 110.7418 KNN MSE: 38.9487 PRE: 0.6483\n",
      "Baseline MSE: 110.9974 KNN MSE: 42.5625 PRE: 0.6165\n",
      "Baseline MSE: 110.3898 KNN MSE: 39.6499 PRE: 0.6408\n",
      "Baseline MSE: 113.4384 KNN MSE: 42.6675 PRE: 0.6239\n",
      "Baseline MSE: 115.6733 KNN MSE: 43.3767 PRE: 0.625\n",
      "Baseline MSE: 116.589 KNN MSE: 40.1695 PRE: 0.6555\n",
      "Overall PRE over 10 trials: 0.6337133121745662\n"
     ]
    }
   ],
   "source": [
    "y=parkinson['total_UPDRS']\n",
    "x=parkinson.drop(['subject#','total_UPDRS','motor_UPDRS'],axis=1) #drop correlated variable and subjectID \n",
    "\n",
    "overall=sum([Knn_estimator(x,y,n_neigh=4) for i in range(10)])/10\n",
    "print(\"Overall PRE over 10 trials:\",overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_model():\n",
    "    scaler = StandardScaler(with_mean=False)\n",
    "    x_std=scaler.fit_transform(x)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_std, y, test_size=0.3)\n",
    "\n",
    "    model=Sequential()\n",
    "    model.add(Dense(19,input_dim=19,activation='sigmoid',kernel_initializer='normal'))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(Adam(lr=0.01),loss='mean_squared_error',metrics=['mse'])\n",
    "    history=model.fit(X_train,y_train,batch_size=20,epochs=100,validation_split=0.1,verbose=0)\n",
    "\n",
    "    pred=model.predict(X_test)\n",
    "    pred_with_mean=[sum(y_test)/len(y_test)]*len(y_test)\n",
    "    baseline=mean_squared_error(y_test,pred_with_mean)\n",
    "    pred_mse=mean_squared_error(list(y_test),pred)    \n",
    "    r_square=(baseline-pred_mse)/baseline\n",
    "    print(\"Baseline MSE:\",round(baseline,4),\"Keras MSE:\",round(pred_mse,4),\"PRE:\",round(r_square,4))\n",
    "    return r_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code works,takes time to run 40%~\n",
    "#overall=sum([keras_model() for i in range(10)])/10\n",
    "#print(\"Overall PRE over 10 trials:\",overall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN is much faster and gives high reduction in error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "song=pd.read_csv('C:/Users/zhenguo/Desktop/STA141C/YearPredictionMSD.csv',header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=song.iloc[:,0]\n",
    "x=song.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Knn_estimator(x,y,n_neigh=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
